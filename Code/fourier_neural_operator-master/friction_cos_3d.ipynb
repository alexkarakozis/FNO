{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "os.environ['export OPENBLAS_NUM_THREADS']='2'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# 3d fourier layers\n",
    "################################################################\n",
    "\n",
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(FNO3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.padding = 15 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(4, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "\n",
    "        self.conv0 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.w0 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x[..., :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 4, 1) # pad the domain if input is non-periodic\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.001 100 0.5\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "DATA_PATH = 'inverse/friction_cos.npy'\n",
    "\n",
    "# currently data are 400 samples\n",
    "ntrain = 350\n",
    "ntest = 50\n",
    "\n",
    "modes = 8\n",
    "width = 20\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "path = f'friction_cos_ep{epochs}'\n",
    "path_model = 'model/'+path\n",
    "path_train_err = 'results/'+path+'train.txt'\n",
    "path_test_err = 'results/'+path+'test.txt'\n",
    "path_image = 'image/'+path\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "S1 = 65\n",
    "S2 = 97\n",
    "T_in = 1\n",
    "T = 1\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 65, 97, 1])\n",
      "torch.Size([50, 65, 97, 1])\n",
      "preprocessing finished, time used: 0.15645109995966777\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# load data\n",
    "################################################################\n",
    "data_gen = np.load(DATA_PATH)\n",
    "\n",
    "# cp = plt.imshow(abs(data_gen[0,:,:,0]-data_gen[10,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(data_gen[0,:,:,0]-data_gen[20,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(data_gen[0,:,:,0]-data_gen[30,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# np.random.shuffle(data_gen)\n",
    "train_a = torch.tensor(data_gen[:ntrain,:,:,:T_in], dtype=torch.float)\n",
    "train_u = torch.tensor(data_gen[:ntrain,:,:,T_in:T+T_in], dtype=torch.float)\n",
    "\n",
    "test_a = torch.tensor(data_gen[-ntest:,:,:,:T_in], dtype=torch.float)\n",
    "test_u = torch.tensor(data_gen[-ntest:,:,:,T_in:T+T_in], dtype=torch.float)\n",
    "\n",
    "print(train_a.shape)\n",
    "print(test_u.shape)\n",
    "assert (S1 == train_u.shape[-3])\n",
    "assert (S2 == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])\n",
    "\n",
    "\n",
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "with open('a_normalizer_friction_cos.pkl', 'wb') as f:\n",
    "    pickle.dump(a_normalizer, f)\n",
    "\n",
    "train_a = a_normalizer.encode(train_a)\n",
    "test_a = a_normalizer.encode(test_a)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "with open('y_normalizer_friction_cos.pkl', 'wb') as f:\n",
    "    pickle.dump(y_normalizer, f)\n",
    "\n",
    "train_u = y_normalizer.encode(train_u)\n",
    "\n",
    "train_a = train_a.reshape(ntrain,S1,S2,1,T_in).repeat([1,1,1,T,1])\n",
    "test_a = test_a.reshape(ntest,S1,S2,1,T_in).repeat([1,1,1,T,1])\n",
    "\n",
    "# train_a = train_a.reshape(ntrain,S1,S2,T_in)\n",
    "# test_a = test_a.reshape(ntest,S1,S2,T_in)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2-t1)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6558357\n",
      "0 2.271940124046523 0.9972064805882318 0.018042809537478856 0.015770254731178282\n",
      "1 2.268690515018534 0.9942883329732077 0.01803716906479427 0.015546386688947677\n",
      "2 2.2705343650304712 0.9998579842703683 0.01804123335650989 0.015615385621786118\n",
      "3 2.2725418740301393 0.9937907989536013 0.017987484101738248 0.01570019155740738\n",
      "4 2.2732469650218263 0.9922190427780151 0.017993788570165634 0.015750200748443605\n",
      "5 2.2757230040151626 0.9925367879016059 0.01798697965485709 0.015694846361875535\n",
      "6 2.276353074994404 0.9937770894595555 0.018024299719503947 0.015816396027803423\n",
      "7 2.27750881400425 0.991422387957573 0.018019872648375374 0.015551835745573044\n",
      "8 2.2780263039749116 0.9878725392477853 0.018028073396001543 0.015637450516223908\n",
      "9 2.2801157439826056 0.9939327022859028 0.017980257762329917 0.015658096969127656\n",
      "10 2.279953484016005 0.9910390641008104 0.017987543514796665 0.01569673091173172\n",
      "11 2.2809990339446813 0.9867305598088674 0.017958022100584847 0.015558319836854935\n",
      "12 2.2797451440128498 0.995078530056136 0.017981852952923094 0.015556536465883255\n",
      "13 2.276949445018545 0.9933363280126026 0.01798336827329227 0.015545864701271056\n",
      "14 2.2776555239688605 0.992450960619109 0.017954049323286328 0.01574089825153351\n",
      "15 2.283639643981587 0.9864151018006461 0.01799852396760668 0.015563227534294129\n",
      "16 2.2861589639796875 0.9926842225449426 0.017973799918379104 0.015610493868589401\n",
      "17 2.2878648529876955 0.9897541755012104 0.017985116647822517 0.01565142199397087\n",
      "18 2.2880045939818956 0.9967656918934413 0.0179957657626697 0.015626968294382097\n",
      "19 2.285421334032435 0.9902825223548072 0.01800694308110646 0.015637926757335663\n",
      "20 2.2871500629698858 0.9896904400416783 0.0179769820187773 0.015657968074083328\n",
      "21 2.286488723999355 0.9891705491713115 0.017975627439362662 0.015697637498378755\n",
      "22 2.2852728140424006 0.9930102459021977 0.018000302910804747 0.015621403306722641\n",
      "23 2.2882383229443803 0.9894332106624331 0.01798269374029977 0.015520865619182587\n",
      "24 2.28780607401859 0.9934635749885015 0.01799829878977367 0.01562900647521019\n",
      "25 2.285173434007447 0.9923719474247523 0.017982306288821356 0.015575369149446487\n",
      "26 2.2867450430057943 0.9901611968874932 0.01796067239982741 0.01563437804579735\n",
      "27 2.289312664011959 0.9911646102155958 0.017965210782630102 0.015582480877637863\n",
      "28 2.288749173982069 0.986226583804403 0.01801327156169074 0.015654703527688982\n",
      "29 2.287014263041783 0.9979474408285959 0.018016558864286967 0.01567384049296379\n",
      "30 2.289685724012088 0.991248607635498 0.017978891560009546 0.015657691359519957\n",
      "31 2.2866199830314144 0.9890515582902091 0.01796830347606114 0.015652859956026076\n",
      "32 2.289526774024125 0.9895684863839831 0.017974288442305156 0.015596079379320145\n",
      "33 2.288170774001628 0.9905116200447083 0.017981722440038407 0.01552497074007988\n",
      "34 2.2897775630117394 0.9899178292070117 0.0179685868535723 0.015614406019449235\n",
      "35 2.290872304001823 0.9951029079301017 0.01798254389848028 0.015634614825248718\n",
      "36 2.290014002996031 0.9893549799919128 0.01796807397689138 0.015615901201963425\n",
      "37 2.2891334340092726 0.9898366510868073 0.017968483418226242 0.015576287358999252\n",
      "38 2.291401272988878 0.9911169435296739 0.017987138884408133 0.015579905956983567\n",
      "39 2.29102707299171 0.9899013672556196 0.017978891027825218 0.015694473683834077\n",
      "40 2.2897229439695366 0.9920360207557678 0.01797536875520434 0.015600589215755462\n",
      "41 2.2879389239824377 0.9913103048290525 0.017978609864200863 0.015623295605182648\n",
      "42 2.2896485730307177 0.9895580538681575 0.017969748015914645 0.015550293177366257\n",
      "43 2.290460573974997 0.9900323301553726 0.017992855821337018 0.015769115537405013\n",
      "44 2.2906502130208537 0.9909123033285141 0.017961511271340505 0.015538947731256485\n",
      "45 2.2910163829801604 0.9917931411947523 0.01797056881444795 0.015568834394216538\n",
      "46 2.290501834009774 0.9903349416596549 0.01797395361321313 0.01571089416742325\n",
      "47 2.2903640429722145 0.9868092949901308 0.017969554236957005 0.015656844079494477\n",
      "48 2.290861833957024 0.9919698093618665 0.017971005056585585 0.015565889179706574\n",
      "49 2.290914912999142 0.9954316271202904 0.017978007537978034 0.015652286261320113\n",
      "50 2.290085313958116 0.9872398665973119 0.017962607826505387 0.0157155442237854\n",
      "51 2.290718622971326 0.9928541711398533 0.01800595360142844 0.015615641921758652\n",
      "52 2.2906164239975624 0.9895969501563481 0.017974647539002554 0.01565901279449463\n",
      "53 2.2910505729960278 0.9880750937121255 0.017975250844444547 0.015646151304244994\n",
      "54 2.291398414003197 0.9887812310031482 0.01797295962061201 0.015693293511867525\n",
      "55 2.292698732984718 0.9929240073476518 0.017987727118389946 0.01562321648001671\n",
      "56 2.29132745298557 0.9955654842512948 0.01801380123410906 0.015605221837759017\n",
      "57 2.29267485399032 0.9873545565775462 0.017977908721991946 0.01575815409421921\n",
      "58 2.292769862979185 0.9895382936511721 0.017966168906007496 0.015589067339897155\n",
      "59 2.2934358729980886 0.9884552896022797 0.017965798314128603 0.015645960867404936\n",
      "60 2.293803384003695 0.9898287389959608 0.017960952797106335 0.015594643354415894\n",
      "61 2.2932485330384225 0.9916310855320521 0.017966267732637268 0.015649409741163255\n",
      "62 2.292941943043843 0.9877171541963304 0.017977512351104192 0.01558243364095688\n",
      "63 2.2884834440192208 0.9932728652443205 0.017968473668609347 0.015598143190145493\n",
      "64 2.29280320298858 0.9897720566817693 0.017961667839969907 0.015667074769735338\n",
      "65 2.291758322971873 0.9897428606237684 0.017973133815186365 0.015627704113721847\n",
      "66 2.29206297401106 0.9895344861916133 0.017988347027982986 0.015594586879014969\n",
      "67 2.2917993430164643 0.9925883795533862 0.017973977540220534 0.015576504468917847\n",
      "68 2.2937554540112615 0.9886003834860665 0.01796882980636188 0.015656124353408813\n",
      "69 2.291240413032938 0.990870932170323 0.017973231949976513 0.015617655664682388\n",
      "70 2.2906105529982597 0.988518967798778 0.017982174924441745 0.015600030571222305\n",
      "71 2.289862193982117 0.9911383867263794 0.01796378397515842 0.015547586381435394\n",
      "72 2.2910969130462036 0.9901921119008745 0.01797386341861316 0.015572907775640488\n",
      "73 2.2916357139474712 0.9878389115844454 0.017983200869389943 0.015609655380249023\n",
      "74 2.2905632730107754 0.9930163800716401 0.017970575519970486 0.015620231330394745\n",
      "75 2.290921013976913 0.9903961798974446 0.017988319567271642 0.015584993809461593\n",
      "76 2.290478293027263 0.9915751291172845 0.018005669734307696 0.01556065410375595\n",
      "77 2.2919785239500925 0.9917308615786689 0.018001997832741055 0.015589920133352279\n",
      "78 2.2909267530194484 0.9930195050580161 0.017997496255806513 0.01569674730300903\n",
      "79 2.2892952740076 0.9898889550140926 0.017960044954504286 0.015552992969751357\n",
      "80 2.2911578729981557 0.9910724537713187 0.0179686278956277 0.015615136325359345\n",
      "81 2.2893538830103353 0.9897699717964444 0.017964624826397213 0.015587057769298553\n",
      "82 2.2902956940233707 0.9895659842661448 0.017969015006508146 0.015589506179094315\n",
      "83 2.2901689729769714 0.9886834391525814 0.017963546855109078 0.015630340576171874\n",
      "84 2.288007843948435 0.9895911646740777 0.01797151437827519 0.015578390955924988\n",
      "85 2.287868914019782 0.9901467097657067 0.017961482597248894 0.01558535560965538\n",
      "86 2.289873532950878 0.9927063226699829 0.017965603406940187 0.015592645555734634\n",
      "87 2.2910061540314928 0.9896617633955819 0.0180109746328422 0.01564370185136795\n",
      "88 2.2884677830152214 0.9935321756771632 0.017984746545553206 0.01563824325799942\n",
      "89 2.2879003639682196 0.9896151346819742 0.017968313757862363 0.01567739576101303\n",
      "90 2.2902426130021922 0.9883740586893899 0.017979315029723303 0.015678070038557052\n",
      "91 2.288835484010633 0.9898155272006989 0.01797812065907887 0.01562971740961075\n",
      "92 2.289398633001838 0.991818709884371 0.01797775040779795 0.015643183141946793\n",
      "93 2.2903392339940183 0.9884729146957397 0.01797137315784182 0.015608848482370376\n",
      "94 2.287718254025094 0.9885440068585533 0.0179680877498218 0.015618481040000916\n",
      "95 2.287911602994427 0.9911367705890111 0.017961670075144088 0.015549072623252868\n",
      "96 2.2886858740239404 0.9890775046178273 0.017982106059789657 0.01562619462609291\n",
      "97 2.2895175530575216 0.9900211900472641 0.017965771364314216 0.015575508177280427\n",
      "98 2.2893203340354376 0.9898178407124111 0.01796123076762472 0.015627271085977553\n",
      "99 2.2913690229761414 0.9906104028224945 0.017967610572065626 0.015538164526224136\n",
      "100 2.288575663988013 0.9911143677575248 0.017963740293468748 0.015596916675567627\n",
      "101 2.2893786329659633 0.990843090415001 0.01795821590082986 0.015601072311401367\n",
      "102 2.2887127040303312 0.9897247987134116 0.017963674047163553 0.015619821101427078\n",
      "103 2.2888019329984672 0.9901788409267153 0.0179589983182294 0.01562731832265854\n",
      "104 2.27789283497259 0.9900691202708654 0.017963092433554786 0.015590113699436187\n",
      "105 2.276924653968308 0.989059386083058 0.01797795361706189 0.01571193054318428\n",
      "106 2.274232854018919 0.9917437485286168 0.017983487908329283 0.01556665003299713\n",
      "107 2.275007624994032 0.9896573288100107 0.017958069443702696 0.015626403987407684\n",
      "108 2.2757452139630914 0.9889404841831753 0.017957587455000198 0.015636437684297563\n",
      "109 2.2758552549639717 0.988959476351738 0.017961570812123163 0.015595246404409409\n",
      "110 2.275590793986339 0.9911252128226417 0.01796370550990105 0.01560093268752098\n",
      "111 2.275756963994354 0.990439703634807 0.017962288430758883 0.015618967860937118\n",
      "112 2.274872404988855 0.9889490438359124 0.01796252088887351 0.015615385323762894\n",
      "113 2.2746562539832667 0.9904976461614882 0.017963302454778125 0.015603594481945038\n",
      "114 2.275668624031823 0.9887352355888912 0.017962666792528968 0.015652329921722413\n",
      "115 2.276330334949307 0.9878760405949184 0.017964137302977697 0.015648391842842103\n",
      "116 2.2756464640260674 0.9898375042847225 0.01796499471579279 0.0155893012881279\n",
      "117 2.2744514450314455 0.9898019867283957 0.017964222090584892 0.015635691583156586\n",
      "118 2.274432994017843 0.9931188455649784 0.017981712732996258 0.015582098811864852\n",
      "119 2.270858664996922 0.9899589168173927 0.017960895278624125 0.015605321675539017\n",
      "120 2.2742114739958197 0.9899120143481663 0.017970515617302486 0.015585009753704072\n",
      "121 2.2756265440257266 0.9888834374291556 0.01795677934374128 0.015643971413373946\n",
      "122 2.2751520649762824 0.9884897223540715 0.01796282919389861 0.015599519312381745\n",
      "123 2.274159584019799 0.9893340868609292 0.0179699470102787 0.01559606909751892\n",
      "124 2.274399785033893 0.9895422037158693 0.017968157955578396 0.015622948110103608\n",
      "125 2.2730499140452594 0.98900645502976 0.01795860386320523 0.015595800131559373\n",
      "126 2.2738901249831542 0.9890003276722772 0.01797440956745829 0.01565601572394371\n",
      "127 2.273161664023064 0.9913414376122611 0.017976248668772832 0.015560187995433808\n",
      "128 2.272769375005737 0.9902319375957761 0.017956953261579787 0.015639450401067734\n",
      "129 2.2724634439800866 0.9903188134942736 0.017961155197450094 0.015622658133506774\n",
      "130 2.2735567550407723 0.9905608211244855 0.01796946067895208 0.015620732754468918\n",
      "131 2.273317104030866 0.988657483458519 0.01795989562358175 0.015646794438362123\n",
      "132 2.2728793749702163 0.9888449553932462 0.01795953516449247 0.01561636209487915\n",
      "133 2.274661073985044 0.9889796827520643 0.017959290061678203 0.015626655369997026\n",
      "134 2.274299644981511 0.990227911727769 0.01795828438230923 0.015599628388881683\n",
      "135 2.2732427539885975 0.9903634233134133 0.0179682648394789 0.015587066411972045\n",
      "136 2.273465845035389 0.9898103326559067 0.017967552947146553 0.015596565753221513\n",
      "137 2.27524035400711 0.9899688827139991 0.017959106202636445 0.015634102821350096\n",
      "138 2.2742669839644805 0.9884606795651573 0.017957848331757953 0.015623060762882232\n",
      "139 2.274516934994608 0.9891657697302955 0.01795655701841627 0.015628431737422944\n",
      "140 2.274675633991137 0.9882187068462371 0.017967392248766763 0.01562510997056961\n",
      "141 2.270720894972328 0.9898581794330052 0.01796097491468702 0.015585616528987885\n",
      "142 2.2703619949752465 0.9909252652100154 0.017959028290850776 0.015606290996074676\n",
      "143 2.2755559840006754 0.9887456723621914 0.017969481625727243 0.015673031806945802\n",
      "144 2.275683754007332 0.9890962647540229 0.017958697399922778 0.015616544038057328\n",
      "145 2.273515934997704 0.9897046651159014 0.017962986145700726 0.015601758658885957\n",
      "146 2.276643524004612 0.9927623782839093 0.017970825284719466 0.015564628839492799\n",
      "147 2.2753381339716725 0.9890339523553848 0.01796638167330197 0.015637432485818864\n",
      "148 2.2748548150411807 0.9893137906278883 0.017955577032906667 0.01561210721731186\n",
      "149 2.27453263400821 0.9897695771285466 0.017964097751038414 0.015595906525850295\n",
      "150 2.27577669499442 0.9894493473427636 0.01796136492065021 0.015650982856750487\n",
      "151 2.276238344027661 0.9905676518167769 0.01796239163194384 0.015577878952026367\n",
      "152 2.2740966440178454 0.9910730391740799 0.017962588923318045 0.015571011453866959\n",
      "153 2.27379758504685 0.989815104007721 0.017968335726431438 0.015619019865989686\n",
      "154 2.2763674539746717 0.9895377014364515 0.017965222001075743 0.015595550239086152\n",
      "155 2.2761421839823015 0.9907578042575291 0.01795988625713757 0.015607015341520309\n",
      "156 2.27672437496949 0.9890189217669624 0.0179629362480981 0.015650345385074614\n",
      "157 2.2745996339945123 0.9875013836792537 0.017961031709398542 0.015636106729507448\n",
      "158 2.275988394045271 0.9896510984216418 0.017961545905896596 0.0155888731777668\n",
      "159 2.275195474969223 0.9921523319823401 0.01796891240136964 0.015604439079761506\n",
      "160 2.2754825740121305 0.9896919527224132 0.01796379402279854 0.01560630977153778\n",
      "161 2.2756396749755368 0.9902152955532074 0.017960395557539803 0.015631655156612398\n",
      "162 2.275445333973039 0.9890631105218615 0.017959201272044863 0.015634481310844422\n",
      "163 2.273319523956161 0.9882890083960124 0.01797376683780125 0.015610705018043519\n",
      "164 2.2739834649837576 0.9897896306855338 0.017962680118424553 0.015618674010038375\n",
      "165 2.276932464039419 0.9898521201951164 0.017964998121772494 0.015644364207983017\n",
      "166 2.2772478940314613 0.9897932938167027 0.017959793976375035 0.015624103844165802\n",
      "167 2.276068184990436 0.9905729370457785 0.017958164917571205 0.015578548610210418\n",
      "168 2.275688783964142 0.9909920202834266 0.017969384768179483 0.01557755023241043\n",
      "169 2.275584763963707 0.9881428263017109 0.01797991265143667 0.0156760473549366\n",
      "170 2.287520213983953 0.9899299255439213 0.017973961234092714 0.015642832666635513\n",
      "171 2.2873883839929476 0.9896024099418095 0.017957193170275006 0.015612128525972366\n",
      "172 2.288058013014961 0.9926295212336949 0.017974856155259268 0.01554188221693039\n",
      "173 2.288735003967304 0.9897783377340862 0.017962513161557062 0.01565341293811798\n",
      "174 2.2881057939957827 0.9886173180171421 0.017962903720991952 0.015643046647310258\n",
      "175 2.2878333329572342 0.9883771257741111 0.017978672853537967 0.015685306489467622\n",
      "176 2.288103583967313 0.9901686923844474 0.017965695836714337 0.01559045970439911\n",
      "177 2.2789981940295547 0.9906051397323609 0.01795934142810958 0.015607976764440536\n",
      "178 2.276417673972901 0.9908382833003998 0.017964646028620856 0.015595491975545883\n",
      "179 2.2764358749845996 0.9901113642113549 0.017959060370922087 0.01562894955277443\n",
      "180 2.2763564939959906 0.9894658518689019 0.017960711142846517 0.015628689378499986\n",
      "181 2.2762236740090884 0.9893809522901262 0.017956513038703374 0.015606901049613953\n",
      "182 2.2748362649581395 0.9891095859663827 0.017959344174180714 0.015624610036611556\n",
      "183 2.275148273969535 0.9890113604920251 0.017967866637877056 0.015642168074846266\n",
      "184 2.2755677640088834 0.9909996756485531 0.017967052779027395 0.015620108842849732\n",
      "185 2.2745875749969855 0.9890103382723672 0.017966242475169047 0.01562671720981598\n",
      "186 2.276003474020399 0.9891812213829585 0.017964666868959155 0.015638240277767182\n",
      "187 2.275657814985607 0.9906337916851043 0.01796743848494121 0.01560718685388565\n",
      "188 2.276831564027816 0.989703283565385 0.01796126710517066 0.015603891462087632\n",
      "189 2.2756836939952336 0.989563775062561 0.017960421038525444 0.0156113700568676\n",
      "190 2.2786694939713925 0.9889064720698766 0.017956863663026266 0.01562107503414154\n",
      "191 2.2766736949561164 0.9887186582599368 0.017964516452380588 0.015653405040502548\n",
      "192 2.274041444004979 0.9894006422587803 0.017958798770393643 0.015611846446990967\n",
      "193 2.273206734971609 0.9924321298088347 0.017970824241638185 0.015618973076343537\n",
      "194 2.274447033996694 0.9907992890902928 0.017969738904918944 0.015633945763111116\n",
      "195 2.2739113140269183 0.9892047873565128 0.017960827669927053 0.015632693618535996\n",
      "196 2.273094214964658 0.9890952791486468 0.017958279507500785 0.015627549290657045\n",
      "197 2.277228514023591 0.9913826073919024 0.017965539182935444 0.015560135096311569\n",
      "198 2.2752117950003594 0.9897000133991242 0.01795875227877072 0.01563342720270157\n",
      "199 2.275035623984877 0.988083119051797 0.017970153646809713 0.015664099901914596\n",
      "200 2.2771797539899126 0.9887410146849496 0.017957804735217776 0.015633372664451597\n",
      "201 2.27680660499027 0.9889453577143805 0.017957792345966613 0.01563533753156662\n",
      "202 2.276777413964737 0.9890173154217856 0.01795788586139679 0.015617206692695618\n",
      "203 2.2759182439767756 0.9895071046692985 0.01795564591884613 0.015602081269025802\n",
      "204 2.277243123971857 0.989434620312282 0.017958037044320786 0.01563319578766823\n",
      "205 2.276969615020789 0.9888068569558007 0.017961744048765726 0.01564756914973259\n",
      "206 2.276875243987888 0.989104083606175 0.01795463808945247 0.015617603659629822\n",
      "207 2.2764515440212563 0.9891376933881215 0.01795488085065569 0.01561737760901451\n",
      "208 2.2743602950358763 0.9894661762884684 0.017956660964659282 0.015596845149993897\n",
      "209 2.276370663952548 0.9889704389231545 0.017961206244570867 0.015638979077339174\n",
      "210 2.2775727540138178 0.9889653640133994 0.017955718891961233 0.01560407057404518\n",
      "211 2.276922465011012 0.9897763460874558 0.017956181125981466 0.015600550025701522\n",
      "212 2.2770656140055507 0.9895306433950152 0.01795459447162492 0.015609956979751587\n",
      "213 2.277285943971947 0.9893439339739936 0.01795616939663887 0.015607854127883911\n",
      "214 2.276127314020414 0.9892235900674547 0.017957190573215483 0.015619846880435944\n",
      "215 2.276166005001869 0.9892191001347133 0.017954146713018416 0.015607006102800369\n",
      "216 2.274933473963756 0.989703691644328 0.017956957753215517 0.015607165545225144\n",
      "217 2.27538700500736 0.9896219023636409 0.017956101660217556 0.015607459396123886\n",
      "218 2.2757828240282834 0.9885818617684501 0.01796782374382019 0.015645801872015\n",
      "219 2.275973003997933 0.9897016120808465 0.017959373933928352 0.01560897022485733\n",
      "220 2.2741123749874532 0.9908357867172786 0.017961612748248236 0.015592028349637986\n",
      "221 2.2738446639850736 0.9897585413285664 0.017961625435522623 0.01564479947090149\n",
      "222 2.2749686149763875 0.9888299575873783 0.01795441672205925 0.015618618428707123\n",
      "223 2.275967554014642 0.9888880308185305 0.017958902014153344 0.015620742589235306\n",
      "224 2.275728133972734 0.9892499817269189 0.01795614806669099 0.015611674785614014\n",
      "225 2.2741940150153823 0.9895577733005796 0.01795628839305469 0.015613850504159928\n",
      "226 2.27626783400774 0.9895136824675969 0.017955861261912755 0.015598796457052231\n",
      "227 2.273240373993758 0.9898700084005083 0.017954400990690504 0.015598882138729096\n",
      "228 2.2772987550124526 0.9892747402191162 0.017959220324243817 0.01561876267194748\n",
      "229 2.287314913002774 0.9892495342663357 0.01795891142317227 0.01563279390335083\n",
      "230 2.288405713974498 0.989048490353993 0.017954556473663875 0.015613697618246079\n",
      "231 2.285612434032373 0.9890665428979056 0.01796089082956314 0.015604091584682464\n",
      "232 2.2851330539560877 0.990041920542717 0.017959227008478983 0.015611464232206345\n",
      "233 2.2898952629766427 0.9901571299348558 0.017957804862942014 0.015610793679952622\n",
      "234 2.289110373996664 0.9893489956855774 0.01795599062527929 0.01561725303530693\n",
      "235 2.2886593629955314 0.9890801702226911 0.017960402518510818 0.015628114491701126\n",
      "236 2.288976333977189 0.9915200097220285 0.01796507381967136 0.015575073659420013\n",
      "237 2.2878364130156115 0.9891797138111932 0.01795897275209427 0.015638545155525208\n",
      "238 2.289163863984868 0.9883545752082552 0.017956804143530982 0.0156374953687191\n",
      "239 2.290266422962304 0.9887128629854747 0.017954947586570468 0.015610551685094834\n",
      "240 2.289455894031562 0.9891528614929744 0.017956692342247282 0.015614499896764755\n",
      "241 2.2903072829940356 0.9898141586354801 0.017960024795361927 0.015582261681556702\n",
      "242 2.290693153976463 0.9900620222091675 0.0179555658357484 0.015607763528823853\n",
      "243 2.287091023987159 0.9894815149051802 0.01795542597770691 0.015613118410110474\n",
      "244 2.291020003031008 0.9893135969127927 0.01795486479997635 0.015622055679559708\n",
      "245 2.2907322630053386 0.989906770842416 0.017958184012344905 0.015601754486560822\n",
      "246 2.2894957439857535 0.989003660423415 0.01795760542154312 0.015630643367767334\n",
      "247 2.2895606529782526 0.9895552047661372 0.017957354720149723 0.015615447759628295\n",
      "248 2.2907206439995207 0.9893576830625535 0.017954813625131336 0.015608226954936981\n",
      "249 2.2893375330022536 0.9892207541636058 0.017956319834504807 0.015609885007143021\n",
      "250 2.2902267040335573 0.9889384363378797 0.017955348044633865 0.015615936517715454\n",
      "251 2.2901714729960077 0.9902974367141724 0.017960301211902074 0.015602652728557587\n",
      "252 2.2883132839924656 0.9901575207710266 0.017960229005132403 0.01561687797307968\n",
      "253 2.2869182340218686 0.9892090559005737 0.017956557146140507 0.015621425211429596\n",
      "254 2.2896032229764387 0.989810803106853 0.01795759724719184 0.015616815686225891\n",
      "255 2.289369153964799 0.989172397341047 0.017954630042825426 0.015614203512668609\n",
      "256 2.289570373017341 0.9894885301589966 0.017960300935166224 0.015609489679336548\n",
      "257 2.2892577539896592 0.9885264030524663 0.017959026630435672 0.01563438981771469\n",
      "258 2.2898927929927595 0.9885384414877211 0.01796235305922372 0.01564354941248894\n",
      "259 2.290412653994281 0.9890166120869773 0.017957447128636495 0.015623781681060791\n",
      "260 2.289942883013282 0.9909739013229097 0.017963135838508604 0.015581066459417344\n",
      "261 2.289975044026505 0.9893821333135877 0.017956914880446026 0.01561767965555191\n",
      "262 2.2891482830164023 0.9889638100351607 0.01795811293380601 0.015637263357639312\n",
      "263 2.290135804039892 0.9887300661631993 0.017957672434193748 0.015636785626411437\n",
      "264 2.2893614229978994 0.9892764696053096 0.017957911491394044 0.015619500875473022\n",
      "265 2.2899567139684223 0.9887801455599922 0.01796121305653027 0.015621603578329086\n",
      "266 2.2898136230069213 0.9894311687776021 0.01795418586049761 0.015596280246973038\n",
      "267 2.289796044002287 0.9908759100096566 0.017959636790411813 0.015584218800067901\n",
      "268 2.2894832529709674 0.9892175082649504 0.017959559048925128 0.015632365494966508\n",
      "269 2.2905842440086417 0.9916410339730126 0.017970829967941557 0.015571846067905426\n",
      "270 2.290031323034782 0.9894226465906416 0.01796002781816891 0.01564445897936821\n",
      "271 2.288955864030868 0.9891412262405668 0.01795839194740568 0.015602950155735016\n",
      "272 2.2900866930140182 0.9893210270575115 0.017956743708678655 0.015622316896915435\n",
      "273 2.290467224025633 0.9899230075734002 0.017959554259266174 0.015618922114372253\n",
      "274 2.2900059730163775 0.9891102092606681 0.017958331406116485 0.015634786039590835\n",
      "275 2.290170284046326 0.9897220773356301 0.017957384905644826 0.015602296590805054\n",
      "276 2.2906215030234307 0.9892615284238543 0.017955465210335596 0.015613573938608169\n",
      "277 2.2919525440083817 0.9892782241106033 0.017955575351204192 0.015620602667331696\n",
      "278 2.290977392985951 0.9895153394767217 0.017960721190486636 0.015619953721761703\n",
      "279 2.2907716640038416 0.9893733595098768 0.017956092378922872 0.015612193793058395\n",
      "280 2.2910118629806675 0.9894066657338824 0.017955413375582013 0.01561919629573822\n",
      "281 2.2917299440014176 0.9892605100359235 0.017956281772681645 0.01562180534005165\n",
      "282 2.2910352330072783 0.990408628327506 0.017960884422063828 0.015610126107931136\n",
      "283 2.2909874029573984 0.9897893641676222 0.01795563382761819 0.015613352805376053\n",
      "284 2.2911028939997777 0.9907512945788247 0.017965786712510246 0.015612195283174514\n",
      "285 2.2905100529897027 0.988523331284523 0.01796237315450396 0.015648978650569915\n",
      "286 2.290014484024141 0.9892733314207622 0.017959344599928175 0.015635084062814712\n",
      "287 2.290572442987468 0.989203748532704 0.017958223138536726 0.01563693434000015\n",
      "288 2.290144964004867 0.9885025386299405 0.017956040650606155 0.015614649206399918\n",
      "289 2.289331862994004 0.9913677845682417 0.01796950706413814 0.015590317994356156\n",
      "290 2.2896678039687686 0.9894057069505964 0.017955092085259302 0.015615374743938447\n",
      "291 2.2875489429570735 0.9902827194758824 0.017962327833686557 0.01560614377260208\n",
      "292 2.2891390540171415 0.9890430424894605 0.01795847318002156 0.015639806389808653\n",
      "293 2.2891463840496726 0.9893409367118563 0.017959523520299368 0.01562821477651596\n",
      "294 2.28956288297195 0.9891246774366924 0.0179549369428839 0.015615525692701339\n",
      "295 2.2883070840034634 0.9895109091486249 0.017962447851896286 0.015608996748924256\n",
      "296 2.2889113029814325 0.9904136168105262 0.017965974999325614 0.01562613680958748\n",
      "297 2.289443533984013 0.9900229730776378 0.017962334709508077 0.015616340637207031\n",
      "298 2.2875043129897676 0.9894383464540754 0.01796176599604743 0.015614368915557862\n",
      "299 2.2907923739985563 0.9889269262552262 0.0179609967981066 0.01563015639781952\n",
      "300 2.289831653004512 0.9891380697488785 0.017955753675528936 0.01561810627579689\n",
      "301 2.2879974140087143 0.9891078808477947 0.017953887752124243 0.01562026172876358\n",
      "302 2.2898506040219218 0.9891012264149529 0.01795480855873653 0.01561539500951767\n",
      "303 2.2892621229984798 0.9888570393834796 0.017955417845930372 0.01562912940979004\n",
      "304 2.288685614010319 0.9887194897447313 0.017954169192484448 0.015624440312385558\n",
      "305 2.2888256330043077 0.9889520151274545 0.01795499710100038 0.0156190687417984\n",
      "306 2.2878758040023968 0.9889182989086424 0.01795540056058339 0.015624209046363831\n",
      "307 2.2886435729451478 0.9889861592224666 0.017956871879952294 0.015616196691989898\n",
      "308 2.287633173982613 0.989304222379412 0.017956287477697643 0.015612101703882218\n",
      "309 2.2918165430310182 0.9895962540592466 0.01795629145843642 0.015607021003961562\n",
      "310 2.2893663439899683 0.9892344151224409 0.017953806455646242 0.015612991154193878\n",
      "311 2.288012153992895 0.9892921852213996 0.017954204997846057 0.015612166821956635\n",
      "312 2.289962323033251 0.9891336143016816 0.017954654970339365 0.015610493421554565\n",
      "313 2.288148584018927 0.9896681410925728 0.017958363677774158 0.015612261891365052\n",
      "314 2.2907896929536946 0.9893276189054762 0.01795581947479929 0.01561944380402565\n",
      "315 2.288744103978388 0.9890678354672023 0.017954513345445906 0.01561992958188057\n",
      "316 2.288853573030792 0.9893351495265961 0.017956815021378653 0.015616771131753922\n",
      "317 2.2886083939811215 0.9890569018466132 0.017955339274236135 0.015616257935762405\n",
      "318 2.2888015029602684 0.9898086833102363 0.01795641730938639 0.015598504841327666\n",
      "319 2.2897180740255862 0.9891558110713958 0.017956962713173458 0.015626375675201417\n",
      "320 2.290047193004284 0.9886452202286039 0.017955661075455803 0.015624122619628906\n",
      "321 2.290464134013746 0.9891416992459978 0.01795395968215806 0.015609984397888183\n",
      "322 2.290349772956688 0.9891110147748675 0.017957226250852856 0.015616447478532792\n",
      "323 2.287799284036737 0.9897761676992689 0.017957274232591903 0.015597490668296814\n",
      "324 2.289807624008972 0.989845278433391 0.017954391006912505 0.015605931729078292\n",
      "325 2.2888146130135283 0.9896660387516022 0.017955415738480432 0.01560494527220726\n",
      "326 2.289868703985121 0.9891248089926583 0.017955118481601987 0.015618714988231659\n",
      "327 2.2893396430299617 0.9889196830136435 0.017955916396209172 0.015618403851985931\n",
      "328 2.290600214037113 0.9889858390603746 0.01795385752405439 0.015613965839147568\n",
      "329 2.2886667029815726 0.9891328752040863 0.01795573170695986 0.015613107979297637\n",
      "330 2.2890510340221226 0.9893010692937033 0.01795486243707793 0.015610536634922028\n",
      "331 2.289055172994267 0.9890347770282201 0.017956393722976957 0.015623332262039184\n",
      "332 2.286176143970806 0.9892748351608004 0.01795502958553178 0.015611954629421235\n",
      "333 2.286809394019656 0.9895376886640276 0.017954974068062644 0.015605288594961166\n",
      "334 2.2880364529555663 0.9889064793075834 0.017956002546208244 0.015620560050010682\n",
      "335 2.2899740539724007 0.9901377213852746 0.017960869755063738 0.015603705942630768\n",
      "336 2.2888075730297714 0.9898090119872774 0.01795793835605894 0.015617562234401703\n",
      "337 2.2882498339749873 0.9894129063401903 0.017955940748964037 0.015612117499113082\n",
      "338 2.2894967339816503 0.9891361300434385 0.017954664932829992 0.015619724094867705\n",
      "339 2.289290622982662 0.9889122473342078 0.017954632214137487 0.015621862262487412\n",
      "340 2.2895485640037805 0.9890703405652728 0.017954109736851284 0.015616909116506577\n",
      "341 2.2898055930272676 0.9892019987106323 0.01795565175158637 0.015617677122354507\n",
      "342 2.288897654041648 0.9897843697241374 0.01795818724802562 0.015603457391262055\n",
      "343 2.287657233013306 0.9890889397689274 0.01795732598219599 0.015626795887947083\n",
      "344 2.287352984014433 0.9890175953507423 0.01795467002051217 0.015613939762115479\n",
      "345 2.2887058439664543 0.9891591908676284 0.017954218834638595 0.015620045065879821\n",
      "346 2.2880090730031952 0.9890753039291926 0.01795500131590026 0.015608538091182709\n",
      "347 2.288742994016502 0.9894167014530727 0.01795461369412286 0.015602610558271408\n",
      "348 2.2889706729911268 0.9890810404505048 0.017956644254071372 0.0156269995868206\n",
      "349 2.288866854039952 0.9887801519462041 0.01795437350869179 0.015622157901525498\n",
      "350 2.289090992999263 0.9888581020491464 0.017954053857496807 0.015617231726646424\n",
      "351 2.2888943440048024 0.989330908868994 0.017956902065447398 0.01560848906636238\n",
      "352 2.287109714001417 0.9891950849975858 0.01795435428619385 0.015608896762132644\n",
      "353 2.289632512954995 0.9897158367293222 0.017955167314835957 0.015599648803472518\n",
      "354 2.289525653992314 0.9895587567772184 0.01795418577534812 0.015610550045967102\n",
      "355 2.2893620030372404 0.988978105357715 0.017956645424876894 0.015618453174829483\n",
      "356 2.2916016139788553 0.9891625102077212 0.017955872608082634 0.015613743960857391\n",
      "357 2.2904558329610154 0.9894086829253605 0.017954228775841848 0.015610407292842864\n",
      "358 2.289083973970264 0.9896197727748326 0.017957768312522344 0.015597838163375854\n",
      "359 2.2868148629786447 0.9894473135471344 0.01795539249266897 0.01560928151011467\n",
      "360 2.2877710339962505 0.9893675080367497 0.017955282075064524 0.015608544498682021\n",
      "361 2.2881218339898624 0.9891741812229157 0.017954205317156656 0.015620159804821015\n",
      "362 2.2886937530129217 0.9893187024763652 0.017955970785447528 0.015608679801225663\n",
      "363 2.29089834401384 0.9886994911091668 0.017957472332886287 0.015628713816404342\n",
      "364 2.288145522994455 0.9895023209708077 0.017957481954778944 0.015613102614879608\n",
      "365 2.287646833981853 0.9893454632588795 0.017954994567802973 0.015610394775867462\n",
      "366 2.2874614240135998 0.9893024444580079 0.017954930939844675 0.015614461451768875\n",
      "367 2.2897398929926567 0.9898509579045432 0.017956491538456507 0.015609376430511475\n",
      "368 2.2887521240045317 0.9893922597169876 0.01795530732188906 0.01560597836971283\n",
      "369 2.289777352998499 0.9893548948424203 0.017954243080956594 0.015618331730365753\n",
      "370 2.2894411939778365 0.9887192730392729 0.017955485156604223 0.015630190819501878\n",
      "371 2.289371252991259 0.9887760034629277 0.017953484164816992 0.015621554851531983\n",
      "372 2.2899742139852606 0.9889598505837577 0.017954388516289846 0.01561810240149498\n",
      "373 2.2874915430438705 0.9892061637980597 0.017955313388790403 0.015611634105443955\n",
      "374 2.290941504004877 0.9893199201141085 0.017954495208603996 0.015610631704330444\n",
      "375 2.2899431430269033 0.9892389663628169 0.017954466385500772 0.015612473636865616\n",
      "376 2.2899346739868633 0.9890772461891174 0.017955209761857986 0.015613400042057038\n",
      "377 2.289554143033456 0.9890627635376794 0.01795558071562222 0.015611708909273148\n",
      "378 2.2909331539995037 0.990036730681147 0.017959413869040354 0.01560832366347313\n",
      "379 2.2906010430306196 0.9889660051890782 0.01795931141291346 0.015628902316093443\n",
      "380 2.2906089239986613 0.9890046996729714 0.017954438690628325 0.015618700534105301\n",
      "381 2.2902616229839623 0.9892817033188683 0.017954855752842766 0.01561154991388321\n",
      "382 2.288847083982546 0.9890885672398976 0.017954781076737814 0.015620995461940766\n",
      "383 2.2904671630240045 0.9892405452472823 0.017955107412167957 0.015604654997587205\n",
      "384 2.289327393984422 0.9894892828805106 0.017954432517290116 0.015612384676933289\n",
      "385 2.290902963024564 0.9892920017242431 0.017959450760057994 0.015603661239147186\n",
      "386 2.2908444739878178 0.9895247144358499 0.017955255593572344 0.015614629089832306\n",
      "387 2.290076222969219 0.9892317848546165 0.01795411324926785 0.015619104504585266\n",
      "388 2.290269524033647 0.9892892028604235 0.01795579465372222 0.015623262971639634\n",
      "389 2.287614732980728 0.9891633604254041 0.017954531865460532 0.01561820238828659\n",
      "390 2.2897121839923784 0.9887936059917722 0.017956781174455372 0.01562444046139717\n",
      "391 2.291016082977876 0.9892641927514757 0.017956036925315857 0.015620942413806915\n",
      "392 2.289928403974045 0.989381017429488 0.017956792967660087 0.015599356442689895\n",
      "393 2.2891556629911065 0.9893375524452754 0.017955855642046246 0.015621177703142166\n",
      "394 2.2890918439952657 0.9892779192754201 0.017954935665641512 0.015612089782953262\n",
      "395 2.2915248629869893 0.9894138212714877 0.017954802896295276 0.015614467412233353\n",
      "396 2.2895596640300937 0.9888062140771321 0.017958674835307258 0.015631315857172014\n",
      "397 2.289548793050926 0.9890530713966914 0.017955179214477538 0.01561588689684868\n",
      "398 2.2902394239790738 0.9897976432527814 0.01795673395906176 0.015598597377538681\n",
      "399 2.2902163329999894 0.9894979940993446 0.017954422065189907 0.015610657334327697\n",
      "400 2.2910859640105627 0.989290634223393 0.01795389575617654 0.01561305969953537\n",
      "401 2.290556852996815 0.9891953174557004 0.01795372818197523 0.015610823780298233\n",
      "402 2.2908343040035106 0.989367134656225 0.017953857417617524 0.015609511137008668\n",
      "403 2.2892247529816814 0.9893667442458016 0.01795389963047845 0.015609560757875443\n",
      "404 2.29046979395207 0.9892704742295402 0.01795416874544961 0.015609884709119797\n",
      "405 2.2873654030263424 0.9891398480960301 0.017955194328512464 0.015619337111711502\n",
      "406 2.291339314018842 0.9890798236642565 0.017955116076128822 0.015622565001249313\n",
      "407 2.290591372991912 0.9890454356159483 0.017953629834311348 0.01561298981308937\n",
      "408 2.2909943140111864 0.9893327219145639 0.017954945926155364 0.015610379427671432\n",
      "409 2.2903784129885025 0.9889924347400665 0.017956405452319555 0.015616130381822586\n",
      "410 2.290186623984482 0.9889862807733673 0.017955556618315834 0.015619098842144012\n",
      "411 2.290933323034551 0.9890472488743919 0.01795392034309251 0.015612145513296127\n",
      "412 2.2899285839521326 0.9893578222819737 0.01795417483363833 0.015606925636529923\n",
      "413 2.290737893024925 0.9891947205577578 0.017954300067254476 0.015616158097982407\n",
      "414 2.289958592969924 0.9892387683902468 0.017954310200044087 0.015612807273864746\n",
      "415 2.2900643539614975 0.9894349438803537 0.017954862884112768 0.015604104399681091\n",
      "416 2.2846370639745146 0.9892894400017602 0.017954401203564237 0.015613511949777604\n",
      "417 2.2798599239904433 0.9890764300312315 0.017953920321805136 0.01561523362994194\n",
      "418 2.2779140440397896 0.98913149195058 0.017955032544476647 0.015610184222459793\n",
      "419 2.2781417140504345 0.9893302087272916 0.017954059690237046 0.01561039313673973\n",
      "420 2.279165724001359 0.989226895570755 0.017954228115933283 0.01561818391084671\n",
      "421 2.279569555015769 0.9889721299920763 0.01795399925538472 0.015617368519306183\n",
      "422 2.2755571139859967 0.989018430028643 0.017953938841819762 0.015615127384662628\n",
      "423 2.285083903989289 0.9890640803745815 0.017953945568629674 0.015613945424556732\n",
      "424 2.2905884430510923 0.9893931069544384 0.01795504127229963 0.015605939328670502\n",
      "425 2.2908238540403545 0.9892434273447309 0.017953822974647794 0.015613096356391907\n",
      "426 2.2901453630183823 0.9893217435904912 0.017954385897942952 0.015609452724456787\n",
      "427 2.289823254046496 0.9895487712962286 0.0179566989839077 0.01561354398727417\n",
      "428 2.290718672971707 0.9896425660167422 0.017957153150013516 0.015604507178068161\n",
      "429 2.288729263993446 0.9891698534999575 0.017953658699989317 0.015615320205688477\n",
      "430 2.290351563016884 0.9892821022442408 0.017955217531749182 0.015615352392196656\n",
      "431 2.2919803239637986 0.9896202577011926 0.017957900315523148 0.015602134913206101\n",
      "432 2.2893164129927754 0.9892446151801518 0.017953183885131563 0.015612838566303253\n",
      "433 2.2904147540102713 0.9891048269612449 0.01795351986374174 0.015616927146911621\n",
      "434 2.2867392429616302 0.9890504087720599 0.01795448143567358 0.015617652237415314\n",
      "435 2.2896409340319224 0.9891605926411492 0.0179539957855429 0.015614918619394302\n",
      "436 2.2898459029966034 0.9889408737421036 0.01795503631234169 0.015620870888233185\n",
      "437 2.290542733971961 0.9890634770904269 0.01795370774609702 0.015616695582866668\n",
      "438 2.2907506229821593 0.9889528602361679 0.01795449578336307 0.015618849396705627\n",
      "439 2.2898111940012313 0.9890194130795342 0.017954725601843424 0.015618198513984681\n",
      "440 2.289944793039467 0.9890542668955666 0.017954329954726355 0.015614516139030456\n",
      "441 2.2890089039574377 0.9894662507942744 0.017954640537500382 0.015605215281248093\n",
      "442 2.288955143012572 0.9892367967537471 0.017954023948737553 0.015618337392807007\n",
      "443 2.2908070939593017 0.9889838474137442 0.017954436114856174 0.015613716095685959\n",
      "444 2.2887936529587023 0.9890089030776705 0.01795519715973309 0.015612527132034301\n",
      "445 2.291001514007803 0.9895160551582064 0.017956627479621342 0.015613162964582443\n",
      "446 2.290913612989243 0.9891520934445518 0.017954086533614567 0.015616306662559509\n",
      "447 2.290724363992922 0.9889585001128061 0.017954531950610024 0.015620747953653336\n",
      "448 2.290966943022795 0.989045450091362 0.01795360062803541 0.015612095296382904\n",
      "449 2.289776294026524 0.9890001667397362 0.017954969448702677 0.015621693879365921\n",
      "450 2.2905837029684335 0.9890343495777675 0.01795586204954556 0.015622840970754623\n",
      "451 2.2899564940016717 0.9890776723623276 0.01795344782727105 0.015613170862197876\n",
      "452 2.290401953039691 0.989214631489345 0.01795379304460117 0.015611935406923294\n",
      "453 2.2909951740293764 0.9891727941376822 0.017954014880316598 0.015615102052688599\n",
      "454 2.291848032968119 0.9894777732236045 0.01795565952147756 0.015609499514102936\n",
      "455 2.2919050729833543 0.9892018522535052 0.017953568207366127 0.015611561536788941\n",
      "456 2.2904793939669617 0.9892629636185509 0.017954002086605345 0.01560957744717598\n",
      "457 2.2852869640337303 0.989124710219247 0.017956448048353196 0.015615480840206147\n",
      "458 2.2883239529910497 0.9893436355250222 0.01795461852635656 0.015611900538206101\n",
      "459 2.289155734004453 0.9891943803855351 0.017953978947230748 0.015613146424293518\n",
      "460 2.291850723035168 0.9891039380005427 0.017955096704619273 0.015614439994096755\n",
      "461 2.2906387639814056 0.9891373421464648 0.017954062862055642 0.0156106935441494\n",
      "462 2.2907797529478557 0.9892315970999854 0.01795409858226776 0.015610986799001693\n",
      "463 2.291099173016846 0.9891603997775487 0.01795424210173743 0.015614585876464844\n",
      "464 2.2899053940200247 0.989262905716896 0.01795478995357241 0.01560749351978302\n",
      "465 2.289911543019116 0.9892420904976981 0.01795377350279263 0.015611526519060136\n",
      "466 2.2856191939790733 0.9889914227383477 0.017956448154790063 0.015623347461223602\n",
      "467 2.285766554006841 0.988871272121157 0.017954478583165578 0.015620214343070983\n",
      "468 2.2895544040366076 0.9890575455767768 0.017953902631998062 0.015614532828330994\n",
      "469 2.2902669540490024 0.9891859914575304 0.017953689758266722 0.015607216060161591\n",
      "470 2.288813444029074 0.9892393265451703 0.017954289040395192 0.015609199106693268\n",
      "471 2.2903025330160744 0.9891470038465091 0.01795460947922298 0.015617998838424683\n",
      "472 2.289923653996084 0.9891855537891387 0.017954003193548746 0.015608578622341156\n",
      "473 2.289818853023462 0.9891997482095446 0.017953902461699076 0.015616321265697479\n",
      "474 2.2890926839900203 0.98924694614751 0.017955639553921564 0.015618479251861573\n",
      "475 2.287389422999695 0.9892336687871388 0.017954499210630144 0.015606330186128616\n",
      "476 2.280128284008242 0.9893676740782601 0.017954136452504568 0.015614015012979508\n",
      "477 2.279345364018809 0.9890694205250059 0.017953715068953376 0.0156154066324234\n",
      "478 2.2801482350332662 0.9893656381538936 0.01795465111732483 0.015609753876924514\n",
      "479 2.2885562329902314 0.9891445653779166 0.017954538826431547 0.015616259276866913\n",
      "480 2.289908253995236 0.9891831798212869 0.01795409864612988 0.015614232122898102\n",
      "481 2.289586623024661 0.989482491356986 0.017955042059932435 0.015606140792369843\n",
      "482 2.288900254003238 0.9892967743532998 0.01795410060456821 0.015608059465885163\n",
      "483 2.289705283008516 0.9891871196883065 0.017954723515680858 0.015621939152479171\n",
      "484 2.288654753996525 0.9889663053410394 0.0179548108790602 0.01561600148677826\n",
      "485 2.2875798829481937 0.9894850654261452 0.01795584031513759 0.015606656074523925\n",
      "486 2.2890809240052477 0.9891515429530825 0.017953832915851047 0.015616766810417175\n",
      "487 2.290655044023879 0.9889575528247015 0.017954051622322626 0.015617709308862686\n",
      "488 2.290064884000458 0.9894995740481786 0.01795721941760608 0.015602328330278397\n",
      "489 2.288987134001218 0.9892656296491623 0.017953257028545652 0.015610267519950866\n",
      "490 2.2897605129983276 0.9891690645899092 0.01795384534767696 0.015614199638366699\n",
      "491 2.28839997400064 0.9890894906861442 0.01795461633375713 0.015616504698991776\n",
      "492 2.2892113929847255 0.9893054221357618 0.01795528239437512 0.015608775466680526\n",
      "493 2.2895179839688353 0.9894173613616398 0.017954173747982298 0.015607317090034484\n",
      "494 2.2882569530047476 0.9890907581363405 0.017953642691884722 0.015616645812988281\n",
      "495 2.289406694006175 0.9892099640199117 0.01795444145798683 0.015612713992595673\n",
      "496 2.289875833026599 0.9891881108283996 0.017953810691833497 0.015615150779485703\n",
      "497 2.289991544035729 0.9890607476234436 0.017953992869172777 0.015612319260835648\n",
      "498 2.290753643028438 0.9891714151416506 0.01795383048909051 0.015614772737026215\n",
      "499 2.2892594839795493 0.9890193930694036 0.017955063858202527 0.015615740716457367\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "model = FNO3d(modes, modes, modes, width).cuda()\n",
    "\n",
    "print(count_params(model))\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "y_normalizer.cuda()\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).view(batch_size, S1, S2, T)\n",
    "\n",
    "        mse = F.mse_loss(out, y, reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        y = y_normalizer.decode(y)\n",
    "        out = y_normalizer.decode(out)\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x).view(batch_size, S1, S2, T)\n",
    "            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_mse, train_l2, test_l2)\n",
    "torch.save(model, path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0022939727641642094\n",
      "0 0.0038156919181346893\n",
      "0 0.005713664926588535\n",
      "0 0.007282788399606943\n",
      "0 0.008410022594034672\n",
      "0 0.009053129702806473\n",
      "0 0.009154172614216805\n",
      "0 0.008620431646704674\n",
      "0 0.007338538765907288\n",
      "0 0.005254779011011124\n",
      "0 0.02572663500905037\n",
      "0 0.02506067231297493\n",
      "0 0.02121925726532936\n",
      "0 0.01564483717083931\n",
      "0 0.009732614271342754\n",
      "0 0.004711025394499302\n",
      "0 0.003847056068480015\n",
      "0 0.007091514766216278\n",
      "0 0.010339259169995785\n",
      "0 0.012882989831268787\n",
      "0 0.014565302059054375\n",
      "0 0.015296869911253452\n",
      "0 0.014984747394919395\n",
      "0 0.013514573685824871\n",
      "0 0.010785817168653011\n",
      "0 0.006856253370642662\n",
      "0 0.0035741422325372696\n",
      "0 0.007879055105149746\n",
      "0 0.014972882345318794\n",
      "0 0.021426664665341377\n",
      "0 0.0161125510931015\n",
      "0 0.00726629514247179\n",
      "0 0.005520007573068142\n",
      "0 0.010726923123002052\n",
      "0 0.016010401770472527\n",
      "0 0.020425254479050636\n",
      "0 0.02375607192516327\n",
      "0 0.0257565937936306\n",
      "0 0.02608005329966545\n",
      "0 0.024318350479006767\n",
      "0 0.020036593079566956\n",
      "0 0.012881055474281311\n",
      "0 0.005125826224684715\n",
      "0 0.01515913661569357\n",
      "0 0.032196007668972015\n",
      "0 0.04854396730661392\n",
      "0 0.04562818259000778\n",
      "0 0.038196057081222534\n",
      "0 0.03218018636107445\n",
      "0 0.02781817689538002\n"
     ]
    }
   ],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "# model = torch.load(\"model/friction_ep500\")\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "first_output = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        if index == 0:\n",
    "            first_output = y.clone()\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(out[:,:,:,0])\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        print(index, test_l2)\n",
    "\n",
    "        # cp = plt.imshow(pred[index])\n",
    "        # plt.colorbar(cp)\n",
    "        # plt.show()\n",
    "\n",
    "# for i in range(18):\n",
    "#     cp = plt.imshow(abs(pred[0,:,:,i]-first_output[0,:,:,i]))\n",
    "#     plt.colorbar(cp)\n",
    "#     plt.show()\n",
    "#     print(i)\n",
    "    # cp = plt.imshow(first_output[0,:,:,i])\n",
    "    # plt.colorbar(cp)\n",
    "    # plt.show()\n",
    "\n",
    "# cp = plt.imshow(first_output[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(pred[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(pred[0,:,:,0]-first_output[0,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(pred[0,:,:,9])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "# cp = plt.imshow(pois_output[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(pred[index][:,:,0] - pois_output[0,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f8c49416430bf6f9356715c0a0173afd7466c7f6261729e3b70b73af4f7e4ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
