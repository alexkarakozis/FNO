{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Zongyi Li\n",
    "This file is the Fourier Neural Operator for 2D problem such as the Navier-Stokes equation discussed in Section 5.3 in the [paper](https://arxiv.org/pdf/2010.08895.pdf),\n",
    "which uses a recurrent structure to propagates in time.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "os.environ['export OPENBLAS_NUM_THREADS']='2'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# 3d fourier layers\n",
    "################################################################\n",
    "\n",
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(FNO3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.padding = 6 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(13, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "\n",
    "        self.conv0 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.w0 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x[..., :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 4, 1) # pad the domain if input is non-periodic\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.001 100 0.5\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "\n",
    "TRAIN_PATH = 'data/ns_V1e-3_N5000_T50.mat'\n",
    "TEST_PATH = 'data/ns_V1e-3_N5000_T50.mat'\n",
    "\n",
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "modes = 8\n",
    "width = 20\n",
    "\n",
    "batch_size = 10\n",
    "batch_size2 = batch_size\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "path = 'nvs_3d'\n",
    "# path = 'ns_fourier_V100_N'+str(ntrain)+'_ep' + str(epochs) + '_m' + str(modes) + '_w' + str(width)\n",
    "path_model = 'model/'+path\n",
    "path_train_err = 'results/'+path+'train.txt'\n",
    "path_test_err = 'results/'+path+'test.txt'\n",
    "path_image = 'image/'+path\n",
    "\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "\n",
    "sub = 1\n",
    "S = 64 // sub\n",
    "T_in = 10\n",
    "T = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 64, 64, 40])\n",
      "torch.Size([200, 64, 64, 40])\n",
      "preprocessing finished, time used: 91.69820549100405\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# load data\n",
    "################################################################\n",
    "\n",
    "reader = MatReader(TRAIN_PATH)\n",
    "train_a = reader.read_field('u')[:ntrain,::sub,::sub,:T_in]\n",
    "train_u = reader.read_field('u')[:ntrain,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "reader = MatReader(TEST_PATH)\n",
    "test_a = reader.read_field('u')[-ntest:,::sub,::sub,:T_in]\n",
    "test_u = reader.read_field('u')[-ntest:,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "print(train_u.shape)\n",
    "print(test_u.shape)\n",
    "assert (S == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])\n",
    "\n",
    "\n",
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "train_a = a_normalizer.encode(train_a)\n",
    "test_a = a_normalizer.encode(test_a)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "train_u = y_normalizer.encode(train_u)\n",
    "\n",
    "train_a = train_a.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "test_a = test_a.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2-t1)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6558537\n",
      "0 15.20831844699569 0.5612365601956845 0.39604634308815 0.23858340263366698\n",
      "1 15.257819174992619 0.11120338622480631 0.18409386348724366 0.14962102293968202\n",
      "2 15.2752894909936 0.05124282285571098 0.12935883474349977 0.11953541934490204\n",
      "3 15.257015654002316 0.0350669315084815 0.10697930306196213 0.10015672236680985\n",
      "4 15.271842929010745 0.02643660318106413 0.0923091059923172 0.08899941295385361\n",
      "5 15.290272735990584 0.021741010649129748 0.08349330353736878 0.08408591836690903\n",
      "6 15.252195873006713 0.018414675937965513 0.0763461993932724 0.07684067845344543\n",
      "7 15.284168953978224 0.015899047246202825 0.0704604001045227 0.07119806975126267\n",
      "8 15.315477013995405 0.01419731811620295 0.0663134628534317 0.06798278421163559\n",
      "9 15.280389271996683 0.01262273573782295 0.06216555219888687 0.06554360300302506\n",
      "10 15.276416631008033 0.011520715542137622 0.05933032628893852 0.061133143603801725\n",
      "11 15.282765673997346 0.011010094559751452 0.05813923329114914 0.06006303608417511\n",
      "12 15.28458392401808 0.009814870189875364 0.0543726581633091 0.05590166583657265\n",
      "13 15.283359743014444 0.009195800037123263 0.052586374700069424 0.05531664684414864\n",
      "14 15.27906475198688 0.008461130266077817 0.050282823860645295 0.05403812289237976\n",
      "15 15.34805538598448 0.00802285517565906 0.04886648911237717 0.05169356346130371\n",
      "16 15.351761847996386 0.007529229349456728 0.04735002839565277 0.0512077821791172\n",
      "17 15.403581764985574 0.007138126138597727 0.04610188573598862 0.049510633498430254\n",
      "18 15.333064161008224 0.006651205564849078 0.044245339393615725 0.04746535703539848\n",
      "19 15.329646148980828 0.006275028483942151 0.04294392141699791 0.046434343606233594\n",
      "20 15.365468981995946 0.006075545540079474 0.04233226120471954 0.04546946793794632\n",
      "21 15.399602794001112 0.005713456261437386 0.04088365653157234 0.043296857327222826\n",
      "22 15.402225974976318 0.005423842479940504 0.039705264776945116 0.04238736778497696\n",
      "23 15.39004935999401 0.0053475279686972495 0.039709383457899095 0.04113483503460884\n",
      "24 15.353334647981683 0.004846098346170038 0.0374460831284523 0.04211998596787453\n",
      "25 15.310694872983731 0.00481276142410934 0.03744229224324226 0.041185484528541566\n",
      "26 15.30170662002638 0.004623534879647196 0.036618292421102525 0.04000099465250969\n",
      "27 15.363376951019745 0.004448242669459432 0.03603885668516159 0.03862135827541351\n",
      "28 15.258473555004457 0.004350892333313823 0.03559522804617882 0.03933992639183998\n",
      "29 15.42884519402287 0.004297738149762154 0.03545456230640411 0.039138273447751996\n",
      "30 15.246642290992895 0.003936455827206373 0.033647863179445264 0.03721215665340424\n",
      "31 15.221038772026077 0.0038058045785874127 0.032972759753465655 0.03886263132095337\n",
      "32 15.23371698599658 0.003731537600979209 0.032753160268068314 0.03666468843817711\n",
      "33 15.146468566003023 0.003556353091262281 0.03193504521250725 0.03533354595303535\n",
      "34 15.146970486006467 0.003511893644463271 0.03179684439301491 0.0374748457968235\n",
      "35 15.19648858398432 0.003534450912848115 0.03191016235947609 0.03468726024031639\n",
      "36 15.178115296992473 0.0033195063984021544 0.030791101068258286 0.036020336002111436\n",
      "37 15.156031420017825 0.003247480276040733 0.03049541872739792 0.03343462109565735\n",
      "38 15.244030000001658 0.0033373389509506524 0.031103181153535844 0.033421455323696135\n",
      "39 15.219550781010184 0.0031134265684522686 0.029853365585207937 0.03235399067401886\n",
      "40 15.18823116098065 0.003017094504320994 0.02924459896981716 0.03262048110365868\n",
      "41 15.194589232996805 0.002978442704770714 0.029141433984041214 0.033110156655311584\n",
      "42 15.235367917019175 0.00292436808347702 0.028853217720985414 0.032823345363140105\n",
      "43 15.257241754006827 0.0028216152417007835 0.02828986756503582 0.031204274892807006\n",
      "44 15.213790779991541 0.0028321661648806184 0.028437788620591164 0.03189544484019279\n",
      "45 15.72090671499609 0.002776057766750455 0.028125829592347145 0.032653416246175765\n",
      "46 28.056098258995917 0.002790406782878563 0.028293163776397706 0.030651462078094483\n",
      "47 28.16530938699725 0.0024900396005250514 0.026327519938349725 0.030072048604488373\n",
      "48 17.452053673012415 0.0024973216536454857 0.026493343636393548 0.03127098441123963\n",
      "49 15.243300489993999 0.0026509855361655354 0.027546776115894317 0.030501596331596374\n",
      "50 15.211835898982827 0.002489931486779824 0.026548010945320128 0.03157928630709648\n",
      "51 15.2200497520098 0.0025970636447891593 0.02743254202604294 0.03053952395915985\n",
      "52 15.15744991999236 0.002404172010719776 0.026115435734391214 0.028436578661203384\n",
      "53 15.219701900990913 0.0023610084352549167 0.02576214101910591 0.029800583869218827\n",
      "54 15.294851547980215 0.002369200704852119 0.025865492597222327 0.029058757349848748\n",
      "55 27.179941075999523 0.0023716949147637935 0.02597051054239273 0.02915903277695179\n",
      "56 28.215427235001698 0.002241192312212661 0.02510021537542343 0.028848281651735305\n",
      "57 19.33040302200243 0.002283006958896294 0.025422593787312507 0.0278813336789608\n",
      "58 15.2905652160116 0.0022295244340784846 0.025102246060967445 0.029356064572930336\n",
      "59 15.308634182991227 0.002312394098844379 0.02568994863331318 0.02946207605302334\n",
      "60 15.285918923997087 0.0020858089113608004 0.024038610458374025 0.02700455665588379\n",
      "61 15.591699400014477 0.002051156982779503 0.023864661604166032 0.0281049744784832\n",
      "62 22.76830148199224 0.002173410760005936 0.024837962731719017 0.03146714076399803\n",
      "63 15.32825347900507 0.0020172115054447205 0.023689932480454444 0.02647567920386791\n",
      "64 15.140950924018398 0.0020110341743566095 0.023672131538391112 0.025620262399315835\n",
      "65 15.257057845010422 0.0019725345983169973 0.02348918454349041 0.027695524841547012\n",
      "66 15.14490994499647 0.001994189565302804 0.0236991745531559 0.026725608780980112\n",
      "67 15.119424727017758 0.0019616764993406833 0.02335275985300541 0.02666262038052082\n",
      "68 15.198338643996976 0.001954074532259256 0.023424805849790575 0.02680548906326294\n",
      "69 17.425388414994814 0.0018828547967132182 0.02285314406454563 0.02597507491707802\n",
      "70 28.01465399400331 0.0018434890627395362 0.022592962205410003 0.028163144811987877\n",
      "71 28.16594197798986 0.0019931114255450667 0.02379008860886097 0.025430935248732568\n",
      "72 28.15891314399778 0.0018519872950855643 0.022658818915486337 0.029999918341636657\n",
      "73 28.116297409986146 0.0021700243395753206 0.02499208587408066 0.02556994467973709\n",
      "74 28.187919354997575 0.001823161542415619 0.02253966635465622 0.025608277320861815\n",
      "75 28.132139055989683 0.0017660742939915508 0.022116558387875556 0.024546253606677056\n",
      "76 28.320803239999805 0.0017511011892929673 0.02201411409676075 0.025441256612539292\n",
      "77 28.37440887998673 0.0018948803562670946 0.023153330594301223 0.025800869539380072\n",
      "78 28.158957695006393 0.0017497528018429874 0.02207899682223797 0.025497198551893235\n",
      "79 28.168290928006172 0.0017330341506749392 0.021936256512999533 0.0245688284188509\n",
      "80 28.142606868990697 0.001810004902072251 0.022621626555919646 0.025463591143488885\n",
      "81 28.127242413000204 0.0017766222171485425 0.022363309666514397 0.024311903193593026\n",
      "82 28.021997456991812 0.001637591264443472 0.021193517908453943 0.025096467435359954\n",
      "83 28.0457204960112 0.0018362621066626162 0.022840294614434244 0.027400771006941795\n",
      "84 28.1600767649943 0.001623764486867003 0.021132169380784036 0.024081940576434136\n",
      "85 28.16611162701156 0.0015981942019425333 0.0209788838326931 0.02407640352845192\n",
      "86 28.186976493976545 0.0016398079099599271 0.021346165984869003 0.02486733004450798\n",
      "87 28.224648907984374 0.0015805921819992364 0.02081149372458458 0.02475866600871086\n",
      "88 38.80826346599497 0.0015419917716644705 0.020559368476271628 0.023778761699795724\n",
      "89 41.20410565499333 0.001623215329600498 0.021289166778326034 0.025259909927845003\n",
      "90 41.24408139800653 0.0016184835031162947 0.021271978333592415 0.024381060153245926\n",
      "91 41.04008879797766 0.001530207023024559 0.02053183276951313 0.023785011246800422\n",
      "92 41.19903673301451 0.0015305974491639062 0.020575728878378868 0.024587461203336717\n",
      "93 41.160616918990854 0.0015219933644402771 0.020520072549581526 0.023871836438775062\n",
      "94 41.29710213598446 0.0016126677813008427 0.021263617008924485 0.02309501767158508\n",
      "95 41.12615991799976 0.001477805314352736 0.020142408698797225 0.02642524227499962\n",
      "96 38.517565076006576 0.0015986937726847827 0.021129468590021135 0.02405841626226902\n",
      "97 27.93289974599611 0.0015449232212267816 0.020713122203946114 0.02277105562388897\n",
      "98 28.00108455098234 0.0014738395705353468 0.020149926722049714 0.024991950094699858\n",
      "99 27.80684554297477 0.0014253103343071416 0.019734526187181474 0.023743005245923997\n",
      "100 27.924325492989738 0.0011503016989445314 0.01718582198023796 0.02027792952954769\n",
      "101 27.846764447021997 0.00110052625881508 0.016727972254157068 0.02040313810110092\n",
      "102 27.691046473017195 0.0011026483215391637 0.01681174547970295 0.02042203225195408\n",
      "103 27.541069550992688 0.0010893203807063401 0.016705356746912002 0.020294815078377725\n",
      "104 27.911492249986622 0.001072966423816979 0.016577584519982338 0.020043288692831993\n",
      "105 27.772333031025482 0.0011038785974960773 0.016883258298039435 0.020541833192110063\n",
      "106 27.733358736993978 0.0010615160927409306 0.0164933393150568 0.020060369074344636\n",
      "107 27.703633818018716 0.0010640614485600962 0.01651823388040066 0.02026574932038784\n",
      "108 27.859042121010134 0.0010567484103376045 0.016501790657639504 0.020276286602020265\n",
      "109 27.99178632698022 0.0010389567114179954 0.016282889381051064 0.0199363049864769\n",
      "110 27.85901323100552 0.0010473248705966398 0.016437105134129524 0.02024601384997368\n",
      "111 27.764546838006936 0.0010354359325719998 0.01633241279423237 0.02007983185350895\n",
      "112 27.758972147013992 0.00104722811258398 0.016449301213026048 0.01998925067484379\n",
      "113 26.894350107002538 0.0010475438786670566 0.016490348517894746 0.0198025281727314\n",
      "114 15.258316515013576 0.0010392642399528996 0.01644314466416836 0.019982131421566008\n",
      "115 15.192729613016127 0.0010145779582671822 0.016179552763700485 0.01977573849260807\n",
      "116 15.387955938989762 0.0010004435147857294 0.016048551589250566 0.020126211196184157\n",
      "117 15.299569639988476 0.0010045757895568385 0.01605461385846138 0.020000495389103888\n",
      "118 15.401566254004138 0.0010431553586386145 0.016568093255162238 0.020385507568717\n",
      "119 15.320170806022361 0.001015877139288932 0.016250757932662965 0.01936490587890148\n",
      "120 15.297548558999551 0.0009946958912769332 0.016033193036913872 0.01933932811021805\n",
      "121 15.329396688990528 0.001001531249494292 0.01617129535973072 0.019640010744333268\n",
      "122 15.332259640999837 0.001018688988406211 0.016354090556502342 0.019650832787156104\n",
      "123 15.320105576014612 0.0009724860423011705 0.015830633893609048 0.01970703363418579\n",
      "124 15.30212090999703 0.000981403334881179 0.01593948923051357 0.020279227197170256\n",
      "125 15.378118377004284 0.0009945682069519535 0.016118288427591325 0.019101590290665625\n",
      "126 15.337911431997782 0.0009746919682947919 0.01595322407782078 0.019924271181225778\n",
      "127 15.314263804000802 0.0009661877417238429 0.01582614706456661 0.01939890153706074\n",
      "128 15.327091538987588 0.0009498405532212928 0.015642507985234262 0.0189456844329834\n",
      "129 15.306964582006913 0.0010383490793174134 0.016703050792217254 0.019444144889712335\n",
      "130 15.297676488000434 0.0009527767973486334 0.01570163716375828 0.018691397830843927\n",
      "131 15.352574407006614 0.0009324969281442464 0.01548269845545292 0.019625057950615882\n",
      "132 15.300303549011005 0.0009091226616874337 0.015271436661481856 0.019432370811700822\n",
      "133 15.29022829499445 0.0009328529116464779 0.015572654858231545 0.01903692342340946\n",
      "134 15.317770235997159 0.0009172888722969219 0.015396561861038207 0.01947607710957527\n",
      "135 15.380752397002652 0.0009355629532365129 0.015599147886037827 0.018766674250364303\n",
      "136 15.321836736984551 0.0009545363090001047 0.015820632189512254 0.019720808863639833\n",
      "137 15.237726947991177 0.0009177898138295859 0.015431279867887497 0.018927214965224266\n",
      "138 15.158675220009172 0.001007140237488784 0.016453061327338217 0.021018772423267364\n",
      "139 15.221131633006735 0.0009182693500770256 0.015469745770096778 0.01899778313934803\n",
      "140 15.196441223000875 0.0009298996248980984 0.01562937109172344 0.018469543680548667\n",
      "141 15.29648873800761 0.0008941630204208196 0.01520172943174839 0.018508707731962205\n",
      "142 15.24273709001136 0.0008766192069742829 0.014957877524197102 0.019086496457457542\n",
      "143 15.180189688020619 0.000926928332191892 0.015631489038467408 0.019658504948019982\n",
      "144 15.267560398002388 0.0009010414953809231 0.015295893356204033 0.01843703381717205\n",
      "145 15.240777648985386 0.000908435985329561 0.015426724091172218 0.018616011291742326\n",
      "146 15.362081371014938 0.0008647895482135937 0.014902427695691585 0.01894118718802929\n",
      "147 15.303440620016772 0.0008624786674045026 0.01488759009540081 0.018630793169140816\n",
      "148 15.31959060599911 0.0008787664060946554 0.015085747614502907 0.018950666263699532\n",
      "149 15.32741085899761 0.0008508540212642401 0.014777021981775761 0.0183040439337492\n",
      "150 15.312520203995518 0.000911884920205921 0.015531156122684478 0.019367786347866057\n",
      "151 15.303205480013276 0.0008628440898610279 0.014934515401721 0.018682819083333014\n",
      "152 15.387217220006278 0.0008784058503806591 0.015146001175045967 0.018761673271656037\n",
      "153 15.355533367983298 0.0008824774960521608 0.015203487858176231 0.01858410269021988\n",
      "154 15.327136879001046 0.0008928082417696715 0.015402098432183266 0.018375464603304862\n",
      "155 15.325780498009408 0.0008405596710508689 0.014728335857391358 0.018156700730323792\n",
      "156 15.295500088017434 0.0008470990159548819 0.014823675237596035 0.018052867501974105\n",
      "157 15.401171934005106 0.0008482306252699345 0.014815009579062462 0.01808964096009731\n",
      "158 15.355187979002949 0.0008144426031503827 0.014438564017415046 0.018448964208364487\n",
      "159 15.304396691004513 0.0008285068394616246 0.014609722763299943 0.018175799027085306\n",
      "160 15.312217892991612 0.0008325211750343442 0.014687251478433609 0.018221841678023338\n",
      "161 15.243305169977248 0.0008128654485335574 0.014487096406519413 0.01800976410508156\n",
      "162 15.147048176993849 0.0008076448237989098 0.014413071550428867 0.018041329532861708\n",
      "163 15.220537060988136 0.000834665631991811 0.014743630647659302 0.018109845593571663\n",
      "164 15.437696006993065 0.0008079221058869734 0.014436726540327072 0.01827844500541687\n",
      "165 15.30518139101332 0.0008075468381866812 0.014453044414520264 0.01783472329378128\n",
      "166 15.3037913699809 0.0008361225167755038 0.014804048098623752 0.01820708453655243\n",
      "167 15.296271628001705 0.000806532998685725 0.014433602273464203 0.018834684789180756\n",
      "168 15.301887230016291 0.0008113995310850442 0.014518200434744359 0.018473157361149788\n",
      "169 15.298549539002124 0.0008118878683308139 0.014539222866296768 0.017652086168527602\n",
      "170 15.339337682991754 0.0007654707290930674 0.013971209548413754 0.01785146154463291\n",
      "171 15.305002660985338 0.0007760412932839245 0.01412640280276537 0.017842530086636544\n",
      "172 15.40680126598454 0.0007984786864835769 0.014451617918908597 0.01854380078613758\n",
      "173 15.345649905997561 0.0008118773723253981 0.014603307411074639 0.018320699334144593\n",
      "174 15.345034213998588 0.0007731619963306002 0.01409103275835514 0.017722710743546487\n",
      "175 15.376448825991247 0.000806097814347595 0.01451532880216837 0.01754191569983959\n",
      "176 15.369278943981044 0.0007745870415237732 0.014119053818285465 0.018020596951246262\n",
      "177 15.32709000800969 0.0008375149441417306 0.014933579243719578 0.018585547730326654\n",
      "178 15.353108518000226 0.0008154601685237139 0.014672075226902961 0.017378438264131546\n",
      "179 15.361934131011367 0.0007582998397992924 0.01394669983536005 0.01750136859714985\n",
      "180 15.332607670017751 0.0007651473506120965 0.014048347756266594 0.017647330239415168\n",
      "181 15.314009814988822 0.0007445204054238275 0.013794069401919842 0.01772952452301979\n",
      "182 15.357508999004494 0.0007729008875321597 0.0141683743968606 0.017705156579613687\n",
      "183 15.550914825988002 0.0007503142760833725 0.013878285095095635 0.017230984419584275\n",
      "184 15.365026121988194 0.0007678648686851374 0.014150274582207203 0.017785339802503585\n",
      "185 15.364188851002837 0.0007827242754865438 0.014305113576352597 0.01778527647256851\n",
      "186 15.317527145991335 0.0007786645693704486 0.014309246934950351 0.01774941325187683\n",
      "187 15.33641871198779 0.0007608767919009551 0.01405901300162077 0.017166143357753752\n",
      "188 15.578046515001915 0.0007366275176173076 0.013749198071658612 0.017411355078220368\n",
      "189 15.347273305989802 0.000739488186663948 0.013805852420628071 0.018198850154876708\n",
      "190 15.400861494010314 0.0007629387138877064 0.014120637245476245 0.017863491922616957\n",
      "191 15.316039544995874 0.0007264254620531574 0.013657776936888695 0.017170762047171592\n",
      "192 15.30768676198204 0.0007829350119573065 0.014367268986999988 0.01918249435722828\n",
      "193 15.198835634015268 0.0008061643817927688 0.014700430288910866 0.017882899940013887\n",
      "194 15.291533287003404 0.0007373582717264071 0.013831221960484981 0.01712390683591366\n",
      "195 15.320617566001602 0.0007408313400810584 0.013822911873459815 0.01688490830361843\n",
      "196 15.322101857018424 0.0007132566790096461 0.013477286413311959 0.017209917306900024\n",
      "197 15.434891665994655 0.0007403352510300465 0.013897866941988468 0.018058865889906885\n",
      "198 15.409726426994894 0.0007284830609569326 0.013727860726416111 0.01705525189638138\n",
      "199 15.298672408011043 0.0007247032542363741 0.013669081136584282 0.017084810212254525\n",
      "200 15.370491334004328 0.0006220056864549405 0.012309442557394504 0.01615944106131792\n",
      "201 15.31344144398463 0.0006042331975186243 0.012071248352527618 0.01617561459541321\n",
      "202 15.335204872011673 0.0005992526028421707 0.012021951831877232 0.015941361039876936\n",
      "203 15.337121262011351 0.0005969762834138237 0.012035711869597435 0.01592984490096569\n",
      "204 15.326150588021846 0.0005932189227314666 0.011951782986521721 0.01635354608297348\n",
      "205 15.362777961010579 0.0005988300850731321 0.012070352852344512 0.01585147611796856\n",
      "206 15.352914027986117 0.000588062274036929 0.011907649844884873 0.015804094448685645\n",
      "207 15.323354077001568 0.0005890699758310802 0.011932273931801319 0.01585912149399519\n",
      "208 15.314582065009745 0.0005926218369859271 0.011985198765993119 0.016003554835915566\n",
      "209 15.324366328015458 0.0005899901341763325 0.01196636188775301 0.015879109874367713\n",
      "210 15.305731380998623 0.0005920837377198041 0.012009664855897427 0.016117040142416952\n",
      "211 15.309311402001185 0.0005940527291386389 0.012066559977829456 0.016037885919213294\n",
      "212 15.33354936100659 0.0005887847428675741 0.011999402709305286 0.015849558748304845\n",
      "213 15.299729960010154 0.0005871824832865968 0.011956598840653896 0.016184665262699127\n",
      "214 15.327905009005917 0.0005836645408999175 0.011933011054992676 0.015828629247844218\n",
      "215 15.343652933981502 0.0005802667752141132 0.01186382357776165 0.015794010609388353\n",
      "216 15.307899612002075 0.0005851127774803899 0.011971373185515404 0.01576314240694046\n",
      "217 15.3360396019998 0.0005895485557266511 0.012032395713031292 0.01592835210263729\n",
      "218 15.346161524998024 0.000574552665639203 0.01180994925647974 0.01572131544351578\n",
      "219 15.317951225995785 0.0005791691792546771 0.011908316679298878 0.01567398678511381\n",
      "220 15.338283402001252 0.000571619528636802 0.01178985096514225 0.015804742947220802\n",
      "221 15.315792504989076 0.000575991879159119 0.011861288093030452 0.015782454609870912\n",
      "222 15.34788165599457 0.0005832446130807511 0.011989258334040642 0.015852606371045113\n",
      "223 15.299483218987007 0.0005701250862330199 0.011789810627698898 0.015695601999759674\n",
      "224 15.310527093010023 0.0005787141330074519 0.011945389799773692 0.015843487270176412\n",
      "225 15.455763153993757 0.0005709434454911389 0.01183734878897667 0.01586341664195061\n",
      "226 15.415537918976042 0.000561167728737928 0.011669284597039222 0.015463696010410786\n",
      "227 15.338744862994645 0.0005643912326195277 0.011721230529248715 0.01576045177876949\n",
      "228 15.340463463013293 0.0005568802458583378 0.011601491205394268 0.01549638319760561\n",
      "229 15.306064331001835 0.0005633957975078374 0.011731094747781754 0.01582876455038786\n",
      "230 15.352204248018097 0.0005674831455689855 0.011825218424201011 0.015798639953136445\n",
      "231 15.313524474011501 0.000569915798259899 0.011854174241423607 0.015672392547130584\n",
      "232 15.327221079001902 0.0005545118940062821 0.01161981415003538 0.015634532682597638\n",
      "233 15.322978167008841 0.0005540795138222165 0.011633059918880462 0.01575733460485935\n",
      "234 15.342997913976433 0.0005648398734047077 0.011803229615092278 0.015595424398779869\n",
      "235 15.295567007997306 0.0005579394011874684 0.011667040318250657 0.01578145459294319\n",
      "236 15.335128310980508 0.0005530069829546846 0.011616744793951512 0.015599387213587761\n",
      "237 15.30127363000065 0.00054447257949505 0.01149348670989275 0.015477120392024517\n",
      "238 15.303320020990213 0.0005459772137692198 0.011510740265250206 0.0154933899641037\n",
      "239 15.345737165014725 0.000543741922301706 0.011492514684796333 0.015640660673379898\n",
      "240 15.309405541978776 0.0005443546792957932 0.011508536502718925 0.015812417902052404\n",
      "241 15.511181092006154 0.0005542035712278448 0.01169649412482977 0.015702835768461227\n",
      "242 15.329664869001135 0.0005451451751287095 0.01155321903526783 0.015666504055261612\n",
      "243 15.305303731991444 0.0005430956336203962 0.011504187591373921 0.015733023881912233\n",
      "244 15.305181080999319 0.0005447725669364445 0.011556280553340912 0.015320402346551418\n",
      "245 15.319387606024975 0.0005559345733490772 0.011735576622188092 0.0154172557964921\n",
      "246 15.349120766011765 0.0005340391153004021 0.011393204137682914 0.015393219329416752\n",
      "247 15.378812556999037 0.0005401339355739765 0.01148771671205759 0.015603135786950589\n",
      "248 15.364090521004982 0.0005391403115936555 0.01148584423214197 0.015651894360780717\n",
      "249 15.303435420995811 0.0005400761408964172 0.01152502778917551 0.015455519556999206\n",
      "250 15.320552855991991 0.0005333598030847497 0.01140387874096632 0.01527179803699255\n",
      "251 15.334612562000984 0.0005267745041055605 0.011307164564728737 0.015304097160696983\n",
      "252 15.318299304984976 0.0005269413761561737 0.011315920263528824 0.015531624630093575\n",
      "253 15.30446725100046 0.0005305395976756699 0.01139141596853733 0.015655122101306915\n",
      "254 15.366040221997537 0.0005387645939481444 0.011521262377500533 0.015501704476773738\n",
      "255 15.309862163005164 0.0005280811313423329 0.011360438115894794 0.015399443842470646\n",
      "256 15.31872927598306 0.0005338660723646171 0.0114625259116292 0.015495279394090176\n",
      "257 15.328019689011853 0.0005274685905897058 0.011358213990926742 0.015650666318833828\n",
      "258 15.300342569011264 0.0005306303413817659 0.011417808465659618 0.015351002402603627\n",
      "259 15.3873378590215 0.0005309299888904207 0.011431789316236974 0.015350273251533509\n",
      "260 15.340230312984204 0.0005212539999047294 0.011274849884212018 0.015085536651313305\n",
      "261 15.308168521994958 0.0005120416334830224 0.011126614645123482 0.01507346585392952\n",
      "262 15.25606723499368 0.0005182335793506354 0.011216234706342221 0.015151620879769324\n",
      "263 15.207647356990492 0.0005209774101967924 0.011303284361958503 0.015564236268401145\n",
      "264 15.295615248003742 0.0005217010309570469 0.011285827957093715 0.015347852893173695\n",
      "265 15.36157216099673 0.0005177321733208373 0.011254819713532925 0.01516915962100029\n",
      "266 15.325593777990434 0.0005158179643331096 0.011213235937058925 0.01509942214936018\n",
      "267 15.309101242019096 0.0005238744881353341 0.011359770499169827 0.01525737475603819\n",
      "268 15.312880073994165 0.0005084541338146665 0.01112533549964428 0.015189823918044567\n",
      "269 15.342663734016242 0.0005069342057686299 0.011087909661233426 0.015704407766461374\n",
      "270 15.27850759201101 0.0005230657031643205 0.011364239245653152 0.015433025136590004\n",
      "271 15.343471044005128 0.0005131398385856301 0.011210128918290138 0.015199982896447181\n",
      "272 15.345548176002922 0.000508340566593688 0.011136802121996879 0.015087015554308891\n",
      "273 15.656343432026915 0.0005201100933481939 0.011333281002938747 0.015107615366578103\n",
      "274 15.328129639005056 0.0005042300221975893 0.01106931808590889 0.01500487457960844\n",
      "275 15.362045900983503 0.0005108286644099281 0.011196599803864955 0.015357097759842873\n",
      "276 15.33299558100407 0.0005028020704048686 0.011060081653296947 0.015101381950080395\n",
      "277 15.39776674300083 0.0005035937821958214 0.01108636873215437 0.014917303845286368\n",
      "278 15.342548893997446 0.0004961652922793291 0.010954552963376045 0.014971155226230621\n",
      "279 15.33044888000586 0.0004970496785244905 0.010987174607813358 0.015401932001113892\n",
      "280 15.341356902994448 0.0005079976093838922 0.011169640094041824 0.015600474253296852\n",
      "281 15.550589204998687 0.0005125000193947926 0.011233422853052616 0.015204525664448737\n",
      "282 15.538133101013955 0.0005003372233477421 0.011028888009488582 0.014858235716819762\n",
      "283 15.336567241989542 0.0004943921402445994 0.01095741131156683 0.014966633431613445\n",
      "284 15.391320341004757 0.0004978172882692889 0.011033016748726369 0.015165683627128602\n",
      "285 15.318466975993942 0.0004895913598011248 0.010872076958417893 0.014844485111534595\n",
      "286 15.322055307013215 0.0004905117515590973 0.010918480210006238 0.01502390779554844\n",
      "287 15.379221116978442 0.0004989665481843986 0.011078615181148051 0.014904388263821601\n",
      "288 15.313739794015419 0.000497383082692977 0.011039902053773403 0.015405164770781994\n",
      "289 15.244660839991411 0.0004942110454430803 0.01099432148784399 0.014986849017441272\n",
      "290 15.372240974014858 0.0004999113862868399 0.01106720719486475 0.01507418941706419\n",
      "291 15.330358329985756 0.0004986777796875685 0.011063436627388 0.015195541381835938\n",
      "292 15.355817089002812 0.000510517772345338 0.011323067642748355 0.015230842754244805\n",
      "293 15.828997122007422 0.00048691054194932804 0.010880514666438103 0.014982023648917675\n",
      "294 15.403884925006423 0.0004984780048835091 0.011105558544397353 0.014830611310899258\n",
      "295 15.339693312998861 0.0004962509102188051 0.011047268271446227 0.014881606549024581\n",
      "296 15.344388484983938 0.0004786171604064293 0.01075505205243826 0.01486254796385765\n",
      "297 15.456212322984356 0.0004846885005827062 0.010870052568614483 0.015400511622428894\n",
      "298 15.371957544994075 0.0004915319083374925 0.010984509870409966 0.014988839365541936\n",
      "299 15.300969349016668 0.000484814522205852 0.010871622927486897 0.014994053542613984\n",
      "300 15.291972196981078 0.0004450493326294236 0.010219143338501453 0.014632982239127158\n",
      "301 15.428798543987796 0.0004369668537401594 0.010093168810009956 0.014330534189939499\n",
      "302 15.802060293004615 0.00043828886729897933 0.010130480587482452 0.014390516318380833\n",
      "303 15.40599578601541 0.0004328523323056288 0.010025411702692508 0.014264871403574943\n",
      "304 15.379783697018865 0.00043227886548265817 0.010022664412856102 0.01435177206993103\n",
      "305 15.993146349006565 0.0004357567770057358 0.01008656296133995 0.014347250796854496\n",
      "306 15.376314724999247 0.00043521307554328815 0.010082402236759663 0.014357400424778462\n",
      "307 15.323870338004781 0.0004306830730638467 0.01000644788891077 0.014330512657761574\n",
      "308 15.442917359003332 0.00043056655355030673 0.010000198267400265 0.014226747527718544\n",
      "309 15.31195793300867 0.00043381453724578023 0.010083428651094437 0.014199697077274323\n",
      "310 15.37574500599294 0.0004319610973470844 0.010053616210818291 0.014365888424217701\n",
      "311 15.324578297993867 0.00043046957754995675 0.010003868766129017 0.014266888312995434\n",
      "312 15.287548864987912 0.00043082221629447303 0.010038574948906899 0.014225526824593543\n",
      "313 15.302804550010478 0.00043005907704355193 0.010029927484691142 0.014284613095223903\n",
      "314 15.330737099982798 0.00043004721170291304 0.010036305516958237 0.014319936707615853\n",
      "315 15.309047441987786 0.0004294546754681505 0.01002991981804371 0.014312780387699604\n",
      "316 15.36001068999758 0.0004273508372716606 0.009988434828817845 0.014331138841807842\n",
      "317 15.310714452993125 0.00042587504984112454 0.009965029150247573 0.014333300739526749\n",
      "318 15.301150369021343 0.0004271600156789646 0.009990231715142727 0.01425260677933693\n",
      "319 15.290334366000025 0.00042481608426896855 0.009953472442924976 0.014314674362540246\n",
      "320 15.327326138998615 0.00042580207576975226 0.009972933486104011 0.014248400814831258\n",
      "321 15.288953906012466 0.00042494618013734 0.00995898152142763 0.014237957522273064\n",
      "322 15.327736069011735 0.0004237164722871967 0.009957230754196644 0.01418001737445593\n",
      "323 15.317808315012371 0.00042893179750535637 0.010053735978901386 0.014317558705806732\n",
      "324 15.291092436003964 0.00042563413036987184 0.010004012525081634 0.014236740842461586\n",
      "325 15.29851578900707 0.0004242385321413167 0.009966064967215062 0.014189838878810406\n",
      "326 15.34911482699681 0.00042179213982308284 0.009916179493069648 0.014175404831767081\n",
      "327 15.294352447002893 0.0004190053589991294 0.009875456728041172 0.014218944981694221\n",
      "328 15.287487885012524 0.00041972605453338474 0.00989523708820343 0.014260353893041611\n",
      "329 15.325910208019195 0.0004194235673639923 0.00989428699016571 0.014179725833237171\n",
      "330 15.310344693018124 0.00041875974275171755 0.009890712775290012 0.014240030497312546\n",
      "331 15.325466338021215 0.00042181914555840196 0.009950032122433186 0.015083057470619679\n",
      "332 15.340061584021896 0.0004215967265190557 0.00995514513552189 0.01413280814886093\n",
      "333 15.302307449979708 0.0004193038295488805 0.009908563800156117 0.0141993872448802\n",
      "334 15.31330564399832 0.00041607622551964596 0.00986610470712185 0.0140945690497756\n",
      "335 15.395299002004322 0.000418246058980003 0.009904309436678886 0.01414042878895998\n",
      "336 15.387060829001712 0.0004141933561186306 0.009819157272577286 0.014123657383024693\n",
      "337 15.332746330997907 0.0004133753103087656 0.00981745383888483 0.014015367478132248\n",
      "338 15.360043419990689 0.0004163350374437869 0.009872891537845135 0.014152255170047283\n",
      "339 15.343089454021538 0.00041398408415261657 0.009834465213119984 0.014097012616693973\n",
      "340 15.347800515999552 0.0004101449993322603 0.009769265480339528 0.014063979275524616\n",
      "341 15.20540358699509 0.0004104096160153858 0.009779761247336864 0.01400548156350851\n",
      "342 15.237530277983751 0.0004113849488203414 0.009798386521637439 0.014223148413002491\n",
      "343 15.222178551979596 0.00042301583336666225 0.01002344211190939 0.01400855280458927\n",
      "344 15.273318449995713 0.00041359780356287957 0.009841783240437508 0.014265405721962452\n",
      "345 15.212856240017572 0.0004109642672119662 0.009801964305341243 0.014055012501776218\n",
      "346 15.240767518000212 0.00040797339985147117 0.009751710660755634 0.014147319942712783\n",
      "347 15.294979188009165 0.0004086725943489 0.009762436531484127 0.014048803225159645\n",
      "348 15.73071154797799 0.00040854588500224056 0.009762530401349067 0.01415249653160572\n",
      "349 15.770910782011924 0.000409773089340888 0.00978269299119711 0.014014560356736183\n",
      "350 22.131222561001778 0.000409121397533454 0.009771801382303238 0.014090822711586952\n",
      "351 29.177286616992205 0.00040799234353471546 0.009767645031213761 0.013998684994876385\n",
      "352 29.27504729098291 0.00040468797116773205 0.0097010443136096 0.014030878581106663\n",
      "353 28.58238581099431 0.00040356863493798303 0.009695839881896973 0.01396593101322651\n",
      "354 28.593480724986875 0.0004042347471113317 0.009715662010014057 0.01402072373777628\n",
      "355 28.607387889991514 0.00040784264041576534 0.00977319648116827 0.01403566062450409\n",
      "356 28.525294720981037 0.00040765160287264734 0.009784007929265499 0.014046236500144004\n",
      "357 28.583573271986097 0.00040474935769452714 0.009725735165178776 0.014027280174195767\n",
      "358 28.604872628988232 0.0004037858164520003 0.009710759818553925 0.013990420997142792\n",
      "359 28.664505369000835 0.00040247888828162106 0.009694655060768127 0.01394638404250145\n",
      "360 28.376904990000185 0.0004030663485173136 0.009716165162622928 0.014080695435404777\n",
      "361 28.33613215602236 0.00040137244359357284 0.009681263104081154 0.01392327282577753\n",
      "362 28.360453494009562 0.0004012274291017093 0.00967409322410822 0.013910224251449109\n",
      "363 28.31789825001033 0.0004005441424669698 0.009666300043463708 0.013943956941366195\n",
      "364 28.247002504998818 0.00040157494659069924 0.009691158719360828 0.014033128693699836\n",
      "365 28.12454927302315 0.0004010098669095896 0.009691659361124039 0.013945786394178867\n",
      "366 27.983206814009463 0.00040307179966475815 0.0097276199311018 0.01417425874620676\n",
      "367 28.08026868698653 0.00040041832806309686 0.009672014184296132 0.013959886617958545\n",
      "368 28.226539958996 0.0003983389506174717 0.009649645529687405 0.01401521246880293\n",
      "369 28.100592053990113 0.0003973726771073416 0.009624854817986488 0.013920758068561554\n",
      "370 28.16752269800054 0.00039538761804578824 0.009600760027766228 0.013982338458299636\n",
      "371 26.709629054006655 0.00039814703894080594 0.00966695060580969 0.013868136778473854\n",
      "372 26.61222151000402 0.0003970972262322903 0.009629855446517467 0.013877053372561931\n",
      "373 26.566341003985144 0.00039515830925665793 0.009604708187282086 0.01393595527857542\n",
      "374 26.846083401003852 0.00039705696486635133 0.009641412034630776 0.013898371830582618\n",
      "375 26.068713082000613 0.0003977350247441791 0.009664504565298557 0.013839916437864303\n",
      "376 27.110186472011264 0.00039196754019940274 0.009545555375516414 0.013979667872190476\n",
      "377 26.83734087800258 0.00039172680961200966 0.009557377725839615 0.013890573643147946\n",
      "378 27.567616381013067 0.00039179226820124313 0.009556355349719525 0.013756022118031978\n",
      "379 27.029230543994345 0.000392696549242828 0.009563159085810185 0.013829950839281083\n",
      "380 28.556415581988404 0.00039245770050911233 0.009578310042619706 0.013799908235669137\n",
      "381 28.164648436999414 0.0003926829225383699 0.009576517708599568 0.013840092793107033\n",
      "382 28.671847571997205 0.0003908634025719948 0.009555955544114113 0.013877687156200408\n",
      "383 27.697037954989355 0.00039191460789879786 0.009572818845510483 0.013836709633469581\n",
      "384 27.29269137501251 0.00039125876210164277 0.009580920793116093 0.013955867998301983\n",
      "385 27.675546098005725 0.00039111415622755885 0.009565452009439469 0.013836315162479877\n",
      "386 27.65625985097722 0.0003893091538338922 0.009530704386532307 0.013899955004453658\n",
      "387 28.101453584997216 0.00038838161184685306 0.009521482057869434 0.013840670399367809\n",
      "388 27.335137070011115 0.00038696745352353903 0.009497792810201645 0.013877303935587407\n",
      "389 27.55278107500635 0.0003899361038929783 0.009560702003538608 0.013765858449041844\n",
      "390 27.729052066017175 0.0003907547592825722 0.009588936582207679 0.013857848271727561\n",
      "391 28.095093693002127 0.0003871857389458455 0.009509711496531964 0.013779872879385948\n",
      "392 28.068422884010943 0.0003853730134142097 0.009480153143405914 0.013850076496601105\n",
      "393 28.003500191000057 0.00038363846309948715 0.009447152636945247 0.013879217058420181\n",
      "394 27.726086915005 0.00039036974165355785 0.009564319938421249 0.01373620230704546\n",
      "395 28.199359979014844 0.0003857623116346076 0.009497979409992694 0.013789606839418411\n",
      "396 28.20391099000699 0.0003872157087607775 0.009534768916666507 0.013763436265289784\n",
      "397 28.422213485988323 0.0003822237771237269 0.009432500012218951 0.013727608621120452\n",
      "398 27.75747054599924 0.0003877939432277344 0.009537999100983142 0.013833562172949313\n",
      "399 28.349518271017587 0.0003837785312498454 0.009466137781739235 0.013775938898324966\n",
      "400 27.836706812988268 0.00036517918910249135 0.009118080891668797 0.013560162782669067\n",
      "401 28.300281714007724 0.0003635907325951848 0.00909044797718525 0.013511491864919662\n",
      "402 27.44351304700831 0.0003627378122473601 0.009075873851776124 0.013558076731860637\n",
      "403 27.645969567995053 0.0003624936190317385 0.009076400578022004 0.013543337173759938\n",
      "404 27.88722658000188 0.0003628161882807035 0.009076816618442535 0.013491401001811027\n",
      "405 28.114689590001944 0.0003638598108955193 0.009106929942965507 0.013550572618842125\n",
      "406 26.587664700986352 0.00036245124982087874 0.009085743129253388 0.013547910675406456\n",
      "407 27.76200249698013 0.0003627604714711197 0.009091833800077439 0.013545958288013936\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "model = FNO3d(modes, modes, modes, width).cuda()\n",
    "# model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
    "\n",
    "print(count_params(model))\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "y_normalizer.cuda()\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).view(batch_size, S, S, T)\n",
    "\n",
    "        mse = F.mse_loss(out, y, reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        y = y_normalizer.decode(y)\n",
    "        out = y_normalizer.decode(out)\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x).view(batch_size, S, S, T)\n",
    "            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_mse, train_l2, test_l2)\n",
    "torch.save(model, path_model)\n",
    "\n",
    "\n",
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(out)\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        print(index, test_l2)\n",
    "        index = index + 1\n",
    "\n",
    "# scipy.io.savemat('pred/'+path+'.mat', mdict={'pred': pred.cpu().numpy()})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f8c49416430bf6f9356715c0a0173afd7466c7f6261729e3b70b73af4f7e4ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
