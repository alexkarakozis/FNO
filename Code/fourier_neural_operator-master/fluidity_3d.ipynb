{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '2'\n",
    "os.environ['export OPENBLAS_NUM_THREADS']='2'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# 3d fourier layers\n",
    "################################################################\n",
    "\n",
    "class SpectralConv3d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul3d(self, input, weights):\n",
    "        # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "        return torch.einsum(\"bixyz,ioxyz->boxyz\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfftn(x, dim=[-3,-2,-1])\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            self.compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfftn(out_ft, s=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class FNO3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(FNO3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.padding = 15 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(4, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "\n",
    "        self.conv0 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.w0 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv3d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x = F.pad(x, [0,self.padding]) # pad the domain if input is non-periodic\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x[..., :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 4, 1) # pad the domain if input is non-periodic\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y, size_z = shape[0], shape[1], shape[2], shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        return torch.cat((gridx, gridy, gridz), dim=-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.001 100 0.5\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# configs\n",
    "################################################################\n",
    "DATA_PATH = 'inverse/rate_factor_line.npy'\n",
    "\n",
    "# currently data are 100 samples\n",
    "ntrain = 80\n",
    "ntest = 20\n",
    "\n",
    "modes = 8\n",
    "width = 20\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 0.001\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "print(epochs, learning_rate, scheduler_step, scheduler_gamma)\n",
    "\n",
    "path = f'rate_factor_line_ep{epochs}'\n",
    "path_model = 'model/'+path\n",
    "path_train_err = 'results/'+path+'train.txt'\n",
    "path_test_err = 'results/'+path+'test.txt'\n",
    "path_image = 'image/'+path\n",
    "\n",
    "runtime = np.zeros(2, )\n",
    "t1 = default_timer()\n",
    "\n",
    "S1 = 65\n",
    "S2 = 97\n",
    "T_in = 1\n",
    "T = 1\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 65, 97, 1])\n",
      "torch.Size([20, 65, 97, 1])\n",
      "preprocessing finished, time used: 0.08306402497692034\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# load data\n",
    "################################################################\n",
    "data_gen = np.load(DATA_PATH)\n",
    "\n",
    "train_a = torch.tensor(data_gen[:ntrain,:,:,:T_in], dtype=torch.float)\n",
    "train_u = torch.tensor(data_gen[:ntrain,:,:,T_in:T+T_in], dtype=torch.float)\n",
    "\n",
    "test_a = torch.tensor(data_gen[-ntest:,:,:,:T_in], dtype=torch.float)\n",
    "test_u = torch.tensor(data_gen[-ntest:,:,:,T_in:T+T_in], dtype=torch.float)\n",
    "\n",
    "print(train_a.shape)\n",
    "print(test_u.shape)\n",
    "assert (S1 == train_u.shape[-3])\n",
    "assert (S2 == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])\n",
    "\n",
    "\n",
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "# with open('a_normalizer_fluidity.pkl', 'wb') as f:\n",
    "#     pickle.dump(a_normalizer, f)\n",
    "\n",
    "train_a = a_normalizer.encode(train_a)\n",
    "test_a = a_normalizer.encode(test_a)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "# with open('y_normalizer_fluidity.pkl', 'wb') as f:\n",
    "#     pickle.dump(y_normalizer, f)\n",
    "\n",
    "train_u = y_normalizer.encode(train_u)\n",
    "\n",
    "train_a = train_a.reshape(ntrain,S1,S2,1,T_in).repeat([1,1,1,T,1])\n",
    "test_a = test_a.reshape(ntest,S1,S2,1,T_in).repeat([1,1,1,T,1])\n",
    "\n",
    "# train_a = train_a.reshape(ntrain,S1,S2,T_in)\n",
    "# test_a = test_a.reshape(ntest,S1,S2,T_in)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "t2 = default_timer()\n",
    "\n",
    "print('preprocessing finished, time used:', t2-t1)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6558357\n",
      "0 5.4205706770299 0.9813390448689461 0.055133331939578055 0.13967427015304565\n",
      "1 1.6207265129778534 0.9630876667797565 0.05459715723991394 0.13624886870384217\n",
      "2 1.457863953022752 0.9062691405415535 0.05290631577372551 0.11909824013710021\n",
      "3 1.197796958964318 0.7193254381418228 0.04614077731966972 0.038925176858901976\n",
      "4 1.6529299109824933 0.32042076205834746 0.02630683034658432 0.06883289366960525\n",
      "5 1.6190975939971395 0.0892537641339004 0.014806599635630847 0.012772174179553985\n",
      "6 1.6497495010262355 0.0526427433360368 0.010193142388015986 0.015063510835170746\n",
      "7 1.6226155440090224 0.03838427516166121 0.008004522183910012 0.021205057948827745\n",
      "8 1.6188804030534811 0.02530423307325691 0.00569134415127337 0.011461970210075379\n",
      "9 1.6439712719875388 0.027068743365816772 0.005225366703234613 0.012585974484682082\n",
      "10 1.6154078940162435 0.02725126873701811 0.004785835789516568 0.013435258716344833\n",
      "11 1.6162985829869285 0.025227701873518527 0.00466823410242796 0.016276469454169273\n",
      "12 1.6534860319807194 0.024302697856910527 0.005024739331565798 0.0194530688226223\n",
      "13 1.6167433930095285 0.02072972187306732 0.004307156801223755 0.0178694948554039\n",
      "14 1.6217405640054494 0.024107615929096937 0.0048013011459261176 0.023828499019145966\n",
      "15 1.6519927410408854 0.02342959912493825 0.004371435870416463 0.02207840755581856\n",
      "16 1.620419604005292 0.022502666572108865 0.0043236326426267626 0.023017514497041702\n",
      "17 1.6357593919965439 0.02392956311814487 0.004982691071927547 0.02190009653568268\n",
      "18 1.633165593026206 0.024196827900595963 0.004569766391068697 0.034668578580021855\n",
      "19 1.614818734000437 0.02217389189172536 0.005160414706915617 0.02075864188373089\n",
      "20 1.6529392910306342 0.02266900462564081 0.004426016239449382 0.027924859896302223\n",
      "21 1.6216513630351983 0.023269974044524133 0.004326201369985938 0.039743879437446596\n",
      "22 1.6218966440064833 0.021539032575674355 0.004530025389976799 0.021176694333553313\n",
      "23 1.6537755209719762 0.021230108803138137 0.004777577216736972 0.024967237934470178\n",
      "24 1.62742181296926 0.0218753736699 0.004328020033426583 0.029573992267251013\n",
      "25 1.6199032239965163 0.020683511742390692 0.004108614381402731 0.026207826286554336\n",
      "26 1.6519732910091989 0.02051740454044193 0.004008521419018507 0.02552800513803959\n",
      "27 1.6317498530261219 0.019850471755489707 0.003531255689449608 0.028156047314405443\n",
      "28 1.6232807629858144 0.019822360016405582 0.0036479172995314 0.027147091180086135\n",
      "29 1.6554417210281827 0.01936991570983082 0.0037680262932553886 0.029236092418432235\n",
      "30 1.604855005047284 0.01951977680437267 0.0035985383205115796 0.028328923881053923\n",
      "31 1.6119766540359706 0.019971040193922818 0.003789885574951768 0.03323970697820187\n",
      "32 1.613006824045442 0.02321258361916989 0.004601145256310701 0.029457616433501244\n",
      "33 1.656589220976457 0.01846165070310235 0.003474857984110713 0.025094670057296754\n",
      "34 1.6207579629844986 0.0200464625377208 0.003693682048469782 0.029235165938735007\n",
      "35 1.6130807339795865 0.01993751572445035 0.0038120313780382275 0.031422235816717145\n",
      "36 1.6570642110309564 0.019019535626284778 0.0036084895953536035 0.02855389527976513\n",
      "37 1.6128120539942756 0.01848856103606522 0.003640290442854166 0.026319682598114014\n",
      "38 1.6175144239678048 0.020322140771895647 0.003740019304677844 0.03696979247033596\n",
      "39 1.6528946409816854 0.019548374228179455 0.0038945178501307966 0.02772199288010597\n",
      "40 1.6224945330177434 0.02016637392807752 0.0038950924295932054 0.025349298492074013\n",
      "41 1.6543231319519691 0.01900569151621312 0.0037265439983457326 0.029217766597867012\n",
      "42 1.6167159129981883 0.019670379580929875 0.003770843124948442 0.031278069317340854\n",
      "43 1.6213497740100138 0.019083989318460226 0.003964786557480693 0.028755707293748857\n",
      "44 1.6507514010299928 0.020778747275471687 0.003803241462446749 0.03427206426858902\n",
      "45 1.6205252339714207 0.0198982001747936 0.0037690472323447465 0.025938896089792253\n",
      "46 1.6177240429678932 0.020274771726690233 0.004360587615519762 0.03306603282690048\n",
      "47 1.6507904920144938 0.020422086585313082 0.004149612342007458 0.033093252778053285\n",
      "48 1.6191073230002075 0.020013833418488503 0.00424305940978229 0.025110863149166107\n",
      "49 1.6189623239915818 0.020382206072099507 0.004014924680814147 0.025888511911034584\n",
      "50 1.612276534026023 0.020667376113124192 0.0044364226050674915 0.03661107420921326\n",
      "51 1.6523561110370792 0.020090166246518493 0.003829739149659872 0.03386952467262745\n",
      "52 1.6155584240332246 0.018878528499044478 0.003739147842861712 0.02823001816868782\n",
      "53 1.5688311870326288 0.019510971498675644 0.0037793422816321254 0.025016076862812042\n",
      "54 1.1124096129788086 0.018167620874010026 0.003535210341215134 0.031879629194736483\n",
      "55 1.6527663620072417 0.018698631320148706 0.0035297506372444333 0.02939782552421093\n",
      "56 1.6204282729886472 0.020409148652106524 0.003632483631372452 0.029822587221860885\n",
      "57 1.650143792037852 0.018585185636766255 0.003759163059294224 0.027173708379268646\n",
      "58 1.6159370329696685 0.018702614586800337 0.0034211284713819624 0.033015666902065276\n",
      "59 1.6151820039958693 0.02011151285842061 0.00362692738417536 0.030353046581149103\n",
      "60 1.6551309219794348 0.018771563074551523 0.003413370042107999 0.0281882394105196\n",
      "61 1.615043593046721 0.018000526004470885 0.003814319521188736 0.026676711067557334\n",
      "62 1.615306983992923 0.01961478521116078 0.0040075479773804545 0.03001464232802391\n",
      "63 1.6229176029446535 0.02024785685352981 0.0036086683627218007 0.028500384464859963\n",
      "64 1.6519659220357426 0.019266635878011584 0.0037406499730423095 0.02616921253502369\n",
      "65 1.6203815930057317 0.0211235829629004 0.00470096874050796 0.029411911219358444\n",
      "66 1.6199823039933108 0.021390069974586368 0.004180625826120376 0.026670998334884642\n",
      "67 1.6548158210352995 0.021171533851884305 0.004179260390810668 0.03104749321937561\n",
      "68 1.6132406939868815 0.021267546922899783 0.004657584289088845 0.026410621032118796\n",
      "69 1.621469343022909 0.019110949826426804 0.004298037802800536 0.0245669174939394\n",
      "70 1.6525486719910987 0.019509467063471675 0.0037837253184989095 0.03653832748532295\n",
      "71 1.6087265239912085 0.019795058527961373 0.003437192435376346 0.030707422643899918\n",
      "72 1.6204887630301528 0.01858925260603428 0.003459186223335564 0.027223017439246176\n",
      "73 1.6527742219623178 0.019539946224540472 0.0037849119631573557 0.02782968357205391\n",
      "74 1.6227968930033967 0.019425086909905076 0.003569398121908307 0.03596973679959774\n",
      "75 1.6196373329730704 0.018515335163101554 0.0033761041238904 0.03133608885109425\n",
      "76 1.6147396439919248 0.019568625488318503 0.0035714165773242713 0.0354072816669941\n",
      "77 1.6568227010429837 0.02554710954427719 0.005314799677580595 0.028024978935718536\n",
      "78 1.6163710239925422 0.020537201780825853 0.004160680319182574 0.03292119391262531\n",
      "79 1.6117995340027846 0.01832039828877896 0.003368256217800081 0.028105626255273818\n",
      "80 1.6582830810220912 0.01798205671366304 0.0034375851042568683 0.02881217412650585\n",
      "81 1.6154419140075333 0.019458855967968702 0.0038412242196500302 0.04041754715144634\n",
      "82 1.6171825930359773 0.019439410883933306 0.0034679417265579106 0.032753973826766015\n",
      "83 1.6579784720088355 0.01878283964470029 0.0036740209208801387 0.03090345934033394\n",
      "84 1.623037132958416 0.018619828741066158 0.003519175318069756 0.03440659604966641\n",
      "85 1.6137907239608467 0.021032265620306134 0.00412065910641104 0.02971644476056099\n",
      "86 1.656300950970035 0.018765641376376152 0.0033912355080246924 0.03507334589958191\n",
      "87 1.6193863329826854 0.01922837202437222 0.0038479588460177184 0.03182344473898411\n",
      "88 1.626934563042596 0.020462362677790225 0.004134268080815673 0.03462429530918598\n",
      "89 1.6533280920120887 0.020991831552237272 0.004279626370407641 0.029016222059726714\n",
      "90 1.626284362981096 0.01997533463872969 0.003853618400171399 0.0332243375480175\n",
      "91 1.607158494007308 0.0192370826844126 0.0037050171755254268 0.0339757677167654\n",
      "92 1.6541749709867872 0.021169058978557587 0.004143885825760663 0.03438085988163948\n",
      "93 1.6216053640237078 0.01955065899528563 0.004127050680108368 0.026619399711489678\n",
      "94 1.6189972630236298 0.019684219267219305 0.0036791634280234574 0.0342239074409008\n",
      "95 1.6363642530050129 0.020285278791561723 0.003974772873334587 0.0288054458796978\n",
      "96 1.6363549120142125 0.019917643046937883 0.004116622102446854 0.029610079526901246\n",
      "97 1.6215122339781374 0.020164905698038638 0.003974175034090877 0.033487538993358615\n",
      "98 1.6502985309925862 0.019176977570168674 0.0033874741988256575 0.03033413104712963\n",
      "99 1.6234446730231866 0.018152297590859234 0.003352801757864654 0.029163238406181336\n",
      "100 1.6230342040071264 0.018838739371858537 0.003488917415961623 0.03505235835909844\n",
      "101 1.6524803310167044 0.018618647009134293 0.003384803142398596 0.03291398100554943\n",
      "102 1.6207464939798228 0.018492133473046124 0.0032716435845941303 0.031396675109863284\n",
      "103 1.4491579730529338 0.01849726215004921 0.0032584229251369835 0.03350689709186554\n",
      "104 1.1912556589813903 0.018328333855606616 0.0033957785461097957 0.02996755689382553\n",
      "105 1.6503923119744286 0.017971782246604562 0.0031974680023267865 0.03399463444948196\n",
      "106 1.6241914930287749 0.018558157375082374 0.0033297351328656077 0.03379034847021103\n",
      "107 1.6106552540441044 0.018845715909264982 0.003315676376223564 0.031693801283836365\n",
      "108 1.6598435909836553 0.018343464005738497 0.003291152487508953 0.030357370525598525\n",
      "109 1.601334364968352 0.018142330343835056 0.003370905271731317 0.03389234058558941\n",
      "110 1.6597245609737001 0.01842581550590694 0.0033003212185576556 0.03289761245250702\n",
      "111 1.6163104730076157 0.018649124656803906 0.003206606791354716 0.03438060842454434\n",
      "112 1.6192984840017743 0.01894313481170684 0.003450320358388126 0.03244472444057465\n",
      "113 1.654011050995905 0.018242691410705447 0.0032846325542777778 0.03226587735116482\n",
      "114 1.6200713440193795 0.01810437545645982 0.003178570419549942 0.03264119625091553\n",
      "115 1.6520973209990188 0.018695969018153846 0.003208481799811125 0.03563560955226421\n",
      "116 1.6224695830023848 0.01873450621496886 0.003357773507013917 0.030745845288038254\n",
      "117 1.6173358840169385 0.019573008525185287 0.0038787784054875375 0.036575710773468016\n",
      "118 1.6567170009948313 0.02033485716674477 0.0038507109275087714 0.03163510710000992\n",
      "119 1.6150481840013526 0.01821725256741047 0.003402587352320552 0.03207910507917404\n",
      "120 1.6270931129693054 0.018463040119968355 0.0032418863382190468 0.03417314551770687\n",
      "121 1.652519152034074 0.018468544469214976 0.0033400007057935 0.03336598575115204\n",
      "122 1.6121917929849587 0.01840027642901987 0.0032983211567625403 0.03285799846053124\n",
      "123 1.6190473040333018 0.01859849481843412 0.0032339547062292693 0.03583045043051243\n",
      "124 1.6526829909998924 0.018251359462738037 0.003352635377086699 0.02973385602235794\n",
      "125 1.6180625740089454 0.018327807309105992 0.003358252439647913 0.03547540530562401\n",
      "126 1.6187130630132742 0.01978693692944944 0.0034758772701025007 0.035428442806005475\n",
      "127 1.6565498519921675 0.018917409470304847 0.0035105673130601646 0.034269367903470994\n",
      "128 1.609928053978365 0.01887688273563981 0.0033355798106640576 0.0316068708896637\n",
      "129 1.636927892046515 0.01836461608763784 0.00343155637383461 0.03221084251999855\n",
      "130 1.6286708530387841 0.01815115357749164 0.0033379986882209776 0.03458173125982285\n",
      "131 1.6186200939700939 0.019810151308774948 0.003443994652479887 0.03788655810058117\n",
      "132 1.654400521016214 0.019164301687851548 0.0034053323324769735 0.036351670324802396\n",
      "133 1.6057227939600125 0.01940536475740373 0.0035581209696829317 0.0352843102067709\n",
      "134 1.6038792050094344 0.01900282083079219 0.003419230179861188 0.03624518662691116\n",
      "135 1.6554912109859288 0.019181253854185343 0.0037556670838966967 0.03393199034035206\n",
      "136 1.6072892940137535 0.01931960112415254 0.0035461515188217165 0.03621329739689827\n",
      "137 1.6270251530222595 0.018685554154217243 0.0034310023067519067 0.03575428500771523\n",
      "138 1.6529585020034574 0.01868967351038009 0.00322088529355824 0.03760851994156837\n",
      "139 1.6212813230231404 0.019243260147050023 0.0033942738315090536 0.03486058376729488\n",
      "140 1.6182377039804123 0.018631044891662896 0.003479718789458275 0.03329615518450737\n",
      "141 1.655462161055766 0.01816179184243083 0.0031205923995003106 0.03675115667283535\n",
      "142 1.620110132964328 0.019118469674140215 0.00335713573731482 0.03638086356222629\n",
      "143 1.6543677620356902 0.018066918943077326 0.003271900163963437 0.03461913727223873\n",
      "144 1.6126757339807227 0.018628388410434127 0.003206750308163464 0.036312738060951234\n",
      "145 1.6205226629972458 0.018578571267426014 0.003251588554121554 0.03611059486865997\n",
      "146 1.6534243110218085 0.019160708179697394 0.003309580939821899 0.038712114095687866\n",
      "147 1.624382604029961 0.018408775213174522 0.003398307645693421 0.03436055481433868\n",
      "148 1.6208952729939483 0.018159843515604734 0.0033847824670374393 0.03477518707513809\n",
      "149 1.6573632709914818 0.019190189545042813 0.00323324641212821 0.037467450648546216\n",
      "150 1.615613283996936 0.018630755483172834 0.0031958191888406874 0.03665429838001728\n",
      "151 1.6211658230167814 0.01830801006872207 0.0031876613153144716 0.03835425674915314\n",
      "152 1.6054831049987115 0.018186408909969032 0.003132467484101653 0.03576341569423676\n",
      "153 1.6573624610318802 0.01863747788593173 0.003145627328194678 0.03813646547496319\n",
      "154 1.5673898060340434 0.01883346203248948 0.0032045866595581175 0.03857869133353233\n",
      "155 1.6517372020171024 0.018380921916104853 0.0032544030575081704 0.03260143175721168\n",
      "156 1.2982045619864948 0.018597317743115127 0.0032105275429785253 0.042112032696604726\n",
      "157 1.3208905819919892 0.01886236236896366 0.003234331659041345 0.03602793850004673\n",
      "158 1.1979602779611014 0.018709776806645095 0.003291988535784185 0.034693670272827146\n",
      "159 0.9826032420387492 0.018931055441498756 0.0034123404417186975 0.036978311091661456\n",
      "160 0.9861570409848355 0.01861042028758675 0.0031786163337528704 0.03587130829691887\n",
      "161 0.9756064520333894 0.019295643200166523 0.003331271489150822 0.0444859154522419\n",
      "162 0.9814008210087195 0.019238528795540333 0.00328257845249027 0.03568154685199261\n",
      "163 0.9881195810157806 0.018694075057283044 0.0033823782810941338 0.039073919877409935\n",
      "164 0.9868708619615063 0.01848855649586767 0.0035145281348377467 0.03437018021941185\n",
      "165 0.982199551013764 0.01949066377710551 0.0035645395750179888 0.046126704663038254\n",
      "166 1.399743597023189 0.019726145430468023 0.0035281353862956165 0.03307735547423363\n",
      "167 1.6560145309777 0.017881434876471758 0.0034411992877721787 0.0389261357486248\n",
      "168 1.6890714690089226 0.018940897774882615 0.0035104229114949702 0.03472047857940197\n",
      "169 1.662853621004615 0.0181134584126994 0.0032685141311958434 0.03787797689437866\n",
      "170 1.6632847109576687 0.019290411844849586 0.003378434805199504 0.0426054447889328\n",
      "171 1.6913817889872007 0.0187594264280051 0.003391750412993133 0.03490482568740845\n",
      "172 1.639934471982997 0.018539794255048037 0.0032598145306110384 0.03974074684083462\n",
      "173 1.6648492310196161 0.018855003523640335 0.003595053078606725 0.03743748366832733\n",
      "174 1.6716592499869876 0.01820839918218553 0.003259428287856281 0.041061374545097354\n",
      "175 1.6771997510222718 0.019190196180716157 0.003263405687175691 0.037024958059191704\n",
      "176 1.6554219909594394 0.01790074398741126 0.0033821410965174437 0.03440631628036499\n",
      "177 1.6462220519897528 0.01932218694128096 0.003450596472248435 0.0432384230196476\n",
      "178 1.6922546490095556 0.019198378548026085 0.004068265156820417 0.03964160904288292\n",
      "179 1.6417383619700558 0.02099012292455882 0.003842617175541818 0.03631568923592567\n",
      "180 1.6596933910041116 0.018283155630342662 0.0037460756953805684 0.03747737631201744\n",
      "181 1.6658792209927924 0.019624204374849796 0.003964028554037213 0.03805952742695808\n",
      "182 1.6727406499558128 0.018973249127157032 0.003815818298608065 0.03768217414617538\n",
      "183 1.6563907809904777 0.020049471873790026 0.00353851648978889 0.0428505789488554\n",
      "184 1.6640720610157587 0.0173293772386387 0.0033775371965020897 0.03641832396388054\n",
      "185 1.6766750499955378 0.01842213317286223 0.003207031125202775 0.04217569455504418\n",
      "186 1.6447261319844984 0.01771160983480513 0.00330512470100075 0.033456438779830934\n",
      "187 1.6632437509833835 0.019435157300904393 0.003676993935368955 0.04165968522429466\n",
      "188 1.694141118961852 0.019453963497653604 0.0038810917641967533 0.035232805833220485\n",
      "189 1.6574497009860352 0.019819425186142325 0.0037134804064407946 0.04449236840009689\n",
      "190 1.6545999420341104 0.019234077772125602 0.00341831361874938 0.03411686159670353\n",
      "191 1.7002021779771894 0.018639004789292812 0.0033821424935013057 0.04079745188355446\n",
      "192 1.6435250020003878 0.01877838373184204 0.0033126736525446177 0.035369567573070526\n",
      "193 1.6464224320370704 0.01805685495492071 0.003152659279294312 0.038106982782483104\n",
      "194 1.6489805119927041 0.019269883283413947 0.003362170699983835 0.03804151378571987\n",
      "195 1.691674058965873 0.01802188460715115 0.0036184010095894337 0.03700465932488441\n",
      "196 1.6590647309785709 0.020084468415006995 0.0036354989279061556 0.04613700173795223\n",
      "197 1.6901956690126099 0.019476203713566065 0.003604592150077224 0.03894023783504963\n",
      "198 1.6548435720033012 0.01830371201504022 0.003183475439436734 0.036541760340332984\n",
      "199 1.6630065009812824 0.018405893933959305 0.0031143587082624437 0.03931448943912983\n",
      "200 1.695000348961912 0.018389007542282343 0.003028931631706655 0.03880742825567722\n",
      "201 1.6639674400212243 0.01828386529814452 0.0030799315078184008 0.04023164324462414\n",
      "202 1.657308432040736 0.018491039401851594 0.0031663395697250963 0.03829943239688873\n",
      "203 1.6622148299939 0.018343731528148055 0.003365555382333696 0.040168216452002525\n",
      "204 1.691739840025548 0.01841121376492083 0.0029622995061799884 0.03916607163846493\n",
      "205 1.6562955709523521 0.018604697776027024 0.0030618856893852354 0.04081125222146511\n",
      "206 1.6534606209606864 0.01880490977782756 0.0034760622540488837 0.03972225710749626\n",
      "207 1.697557428968139 0.01869938161689788 0.00307042826898396 0.03844571635127068\n",
      "208 1.6490385020151734 0.018269347841851413 0.0030643598875030875 0.04238267242908478\n",
      "209 1.694482008984778 0.01787006505765021 0.0030841216444969176 0.039621753990650176\n",
      "210 1.6561609610216692 0.018203055020421743 0.0030269666574895384 0.03839906826615334\n",
      "211 1.6647419009823352 0.018478366313502192 0.0030525102280080318 0.03999406173825264\n",
      "212 1.6571366810239851 0.01800395967438817 0.003190796240232885 0.040681580826640126\n",
      "213 1.6765372199588455 0.018443355918861926 0.003016421524807811 0.03855555430054665\n",
      "214 1.3117435419699177 0.01840076455846429 0.0030618417775258424 0.041624873876571655\n",
      "215 1.3853200169978663 0.018209346453659236 0.003101643128320575 0.038732067495584485\n",
      "216 1.6604654710390605 0.01822482596617192 0.0030698291258886455 0.040069940686225894\n",
      "217 1.6857731100171804 0.018278551753610373 0.0031617465429008007 0.041434145718812945\n",
      "218 1.652477871044539 0.01832628808915615 0.003092282824218273 0.038977058976888655\n",
      "219 1.6614327210118063 0.018579492694698274 0.003056508721783757 0.04165552891790867\n",
      "220 1.6956976489746012 0.01821665046736598 0.0030699001159518956 0.040631814301013945\n",
      "221 1.6433237319579348 0.018454845063388348 0.003021057485602796 0.04071009457111359\n",
      "222 1.6582464420353062 0.018221912439912558 0.002997325104661286 0.04099443107843399\n",
      "223 1.6904811689746566 0.018223307328298688 0.003035143320448697 0.03958406299352646\n",
      "224 1.6711491900496185 0.01800866751000285 0.0030302141094580293 0.04028448536992073\n",
      "225 1.6554123410023749 0.01788538065738976 0.0030082694487646223 0.03974466770887375\n",
      "226 1.6954637590097263 0.018359003704972565 0.0030196827836334707 0.04068017229437828\n",
      "227 1.6615763410227373 0.01839859876781702 0.0030613876646384598 0.040356901660561564\n",
      "228 1.6622313809930347 0.01824125903658569 0.0030267470283433795 0.04116565510630608\n",
      "229 1.6771011499804445 0.018273582798428833 0.003052979172207415 0.041497844457626346\n",
      "230 1.6615932210115716 0.01805581687949598 0.0030988302314653993 0.040374109894037245\n",
      "231 1.6724885909934528 0.018710387405008078 0.003100470721255988 0.039829027652740476\n",
      "232 1.6908216190058738 0.018135322956368327 0.003032075171358883 0.043303012102842334\n",
      "233 1.629945382999722 0.018420087173581123 0.003175445692613721 0.039850706607103346\n",
      "234 1.6583245510119013 0.01914648513775319 0.0032334044808521867 0.042075983434915545\n",
      "235 1.6839892489952035 0.018091347184963524 0.0031766910571604965 0.04350759647786617\n",
      "236 1.65716100204736 0.01811482710763812 0.0030575212789699436 0.0371645987033844\n",
      "237 1.6684808100108057 0.018076860811561346 0.003062940761446953 0.042700506001710894\n",
      "238 1.699619919003453 0.017971738590858877 0.0031242293771356344 0.040206655859947205\n",
      "239 1.6559901509899646 0.018563396180979908 0.0030651261564344167 0.04069517329335213\n",
      "240 1.6544767119921744 0.018265350139699876 0.003197002224624157 0.041707870364189145\n",
      "241 1.6954286379623227 0.018283466575667262 0.003044207813218236 0.04149978309869766\n",
      "242 1.6518391220015474 0.018040238646790385 0.0029991310322657226 0.04307456687092781\n",
      "243 1.654255970963277 0.018015499226748943 0.0032643579645082353 0.042852678522467616\n",
      "244 1.6933659889618866 0.019464305718429387 0.0035175923258066177 0.03955395296216011\n",
      "245 1.647638021968305 0.01816425856668502 0.0032377163646742702 0.047258463501930234\n",
      "246 1.6547849420458078 0.018415723112411797 0.0031867175130173564 0.03955454379320145\n",
      "247 1.698540868004784 0.018334838561713696 0.0030756150372326374 0.041283486783504485\n",
      "248 1.6494559019920416 0.018275105278007686 0.0031047981465235353 0.041438765823841095\n",
      "249 1.6524022619705647 0.018112687510438263 0.0029914301820099356 0.04257044419646263\n",
      "250 1.698747297981754 0.018843181431293488 0.0032591700553894045 0.039091482385993005\n",
      "251 1.6551639219978824 0.018344518495723605 0.0031861687544733285 0.04344608597457409\n",
      "252 1.6437676720088348 0.01833390083629638 0.0031272902386263015 0.039059845730662346\n",
      "253 1.693223319016397 0.018151874537579715 0.0031016800086945294 0.04204139485955238\n",
      "254 1.6411705820355564 0.01813181454781443 0.0030140462331473827 0.04008143842220306\n",
      "255 1.6494671020191163 0.018426988506689668 0.00317094624042511 0.04497261494398117\n",
      "256 1.695244768052362 0.018377390108071268 0.0030603997875005007 0.03905589506030083\n",
      "257 1.6498529519885778 0.01836429280228913 0.0030166498152539136 0.04330214411020279\n",
      "258 1.643133511999622 0.018342728610150516 0.0030615637311711907 0.04066093303263187\n",
      "259 1.6919246590114199 0.018030157196335495 0.003058426361531019 0.04358402453362942\n",
      "260 1.6522333120228723 0.01831408601719886 0.0030277620535343885 0.041511669754981995\n",
      "261 1.646832791971974 0.018471538671292365 0.00313722335267812 0.04408089779317379\n",
      "262 1.656509420950897 0.018209496280178428 0.0030081678414717317 0.04067375883460045\n",
      "263 1.691216549021192 0.01855157280806452 0.0031116110505536197 0.04357528239488602\n",
      "264 1.2224749670131132 0.01843008352443576 0.0031362553127110004 0.041620510444045064\n",
      "265 1.469310573011171 0.017966712592169642 0.0031000663060694934 0.04464360997080803\n",
      "266 1.6793266899767332 0.018461090279743075 0.0030118011636659503 0.04098923802375794\n",
      "267 1.6592716909945011 0.018276209360919893 0.002991323941387236 0.04325689375400543\n",
      "268 1.6595040509710088 0.018326596007682383 0.003034048876725137 0.04257763251662254\n",
      "269 1.66114761098288 0.018074149382300675 0.0029543968616053463 0.043759693205356595\n",
      "270 1.6903940190095454 0.017813205835409462 0.0029709246242418884 0.04180542156100273\n",
      "271 1.6587965509970672 0.018851404427550733 0.003119643754325807 0.04282031655311584\n",
      "272 1.6478944919654168 0.018178948084823787 0.0032529438845813274 0.046632878482341766\n",
      "273 1.6799587499699555 0.019404246006160975 0.003505159169435501 0.041080542653799054\n",
      "274 1.6505830109817907 0.018483613268472254 0.0030908676562830806 0.046505202725529673\n",
      "275 1.6573319419985637 0.018359417328611016 0.003154607815667987 0.04230135567486286\n",
      "276 1.693788988981396 0.018168639740906656 0.003043112298473716 0.04359036833047867\n",
      "277 1.6478422909858637 0.01831708732061088 0.0030519488267600537 0.0427201222628355\n",
      "278 1.646554252016358 0.01830563775729388 0.003084666607901454 0.04280263334512711\n",
      "279 1.6922557189827785 0.01837897556833923 0.0030094863381236792 0.043790184706449506\n",
      "280 1.654378501989413 0.0181767619214952 0.002994967019185424 0.043163036555051805\n",
      "281 1.6578952310374007 0.018585000303573906 0.0030590984504669906 0.04350147731602192\n",
      "282 1.692168269015383 0.018152181524783373 0.002979187318123877 0.04324065968394279\n",
      "283 1.6572124810190871 0.017864390509203076 0.0031005293829366566 0.04318496584892273\n",
      "284 1.6924225189723074 0.018275336595252156 0.002968187257647514 0.042429867386817935\n",
      "285 1.6513145919889212 0.018311187159270048 0.0030704344622790813 0.04505988582968712\n",
      "286 1.6630912410328165 0.0179509095614776 0.0030767465010285377 0.04372392520308495\n",
      "287 1.6938609989592806 0.018748608301393688 0.0030452597187832 0.042703967168927194\n",
      "288 1.662748631031718 0.017817621119320393 0.0032166595803573726 0.04498327821493149\n",
      "289 1.6555137310060672 0.01819986815098673 0.002963322214782238 0.04217301830649376\n",
      "290 1.6983750790241174 0.017959883087314665 0.002993826102465391 0.044392360001802446\n",
      "291 1.6501565310172737 0.01823825656902045 0.0030035800999030473 0.04321578294038773\n",
      "292 1.6583005219581537 0.018145604291930795 0.0030735846143215896 0.04443450719118118\n",
      "293 1.7036066279979423 0.0186059478437528 0.003068641503341496 0.043631451576948165\n",
      "294 1.6536439210176468 0.01838049804791808 0.0030014469055458905 0.04463758766651153\n",
      "295 1.657519501983188 0.017865855479612947 0.002985221054404974 0.04403788223862648\n",
      "296 1.6940671890042722 0.01829047512728721 0.002969705662690103 0.04427362084388733\n",
      "297 1.6672053000074811 0.018375866813585162 0.0029777716379612686 0.045271700620651244\n",
      "298 1.6475484920083545 0.018157385638915002 0.003005128330551088 0.04274814128875733\n",
      "299 1.6950799189507961 0.0176322590559721 0.002978661376982927 0.04404406733810902\n",
      "300 1.6479790020384826 0.0186087858164683 0.00315175533760339 0.043323587998747824\n",
      "301 1.6293053129920736 0.01818371715489775 0.003041220083832741 0.04823466800153255\n",
      "302 1.6976597280008718 0.018038286245428026 0.002961075841449201 0.04364955835044384\n",
      "303 1.6533357120351866 0.018459432758390903 0.0029945259913802145 0.04365617334842682\n",
      "304 1.6838711900054477 0.018199862097389996 0.003003156720660627 0.045640711486339566\n",
      "305 1.665519209986087 0.018166407477110624 0.0030242665903642773 0.044472507387399676\n",
      "306 1.6606147309648804 0.01798812171909958 0.002919067814946175 0.04431796334683895\n",
      "307 1.700221478997264 0.01816827105358243 0.002934247744269669 0.04360037297010422\n",
      "308 1.6621115009766072 0.018072977429255843 0.0029562265146523712 0.04507877603173256\n",
      "309 1.6521803310024552 0.018082771566696465 0.0029614325845614075 0.04483317621052265\n",
      "310 1.6955516989692114 0.018041197676211596 0.0029484510654583574 0.04448729120194912\n",
      "311 1.6597465010127053 0.018572329194284976 0.003174636443145573 0.04404110684990883\n",
      "312 1.6192833540262654 0.018025293364189565 0.0029167150845751167 0.04559039771556854\n",
      "313 1.6893228290136904 0.018353209947235882 0.002988341497257352 0.044651401415467265\n",
      "314 1.6507611620472744 0.01835343602579087 0.002972221956588328 0.04478759765625\n",
      "315 1.5922798350220546 0.017927772947587073 0.002907208981923759 0.04510279819369316\n",
      "316 1.0995669040130451 0.017936771269887686 0.0029238773975521328 0.04464817196130753\n",
      "317 1.6948533189715818 0.01793687290046364 0.002909830724820495 0.044191768020391466\n",
      "318 1.637786632985808 0.018174030352383852 0.0029729830101132395 0.04388019517064094\n",
      "319 1.6774525200016797 0.0179179614642635 0.0029238608200103044 0.04564998969435692\n",
      "320 1.6687955400557257 0.01797069946769625 0.002945334231480956 0.04452654607594013\n",
      "321 1.665211470972281 0.018172987620346248 0.0029630719684064387 0.045160901919007304\n",
      "322 1.659151520987507 0.018106869305483997 0.0029175115516409276 0.04509300738573074\n",
      "323 1.6967200890067033 0.018100470770150423 0.0029582125833258035 0.044974717870354654\n",
      "324 1.6593610609997995 0.018259858712553978 0.002989463531412184 0.04397620037198067\n",
      "325 1.6738407300435938 0.018199852667748928 0.0029723595594987272 0.04611391797661781\n",
      "326 1.6753351299557835 0.017997615854255855 0.0029345053248107434 0.044395966455340385\n",
      "327 1.6595626710331999 0.018209562287665904 0.0030157148605212568 0.045941706746816635\n",
      "328 1.6701557809719816 0.017933279741555452 0.002919739345088601 0.04428405128419399\n",
      "329 1.6895154389785603 0.017973699956201017 0.0029304946307092904 0.04519905708730221\n",
      "330 1.6565759109798819 0.017993237474001944 0.0029145576525479557 0.04487032033503056\n",
      "331 1.6566166420234367 0.01815668656490743 0.0030143224168568848 0.04525047577917576\n",
      "332 1.696530608984176 0.018173525924794376 0.002933843620121479 0.046237507835030556\n",
      "333 1.667980880010873 0.018038577865809202 0.002922017406672239 0.04514410346746445\n",
      "334 1.6684152410016395 0.018169044866226614 0.002963462029583752 0.044887181371450424\n",
      "335 1.6866770989727229 0.018096084939315915 0.0029302931856364013 0.04555821642279625\n",
      "336 1.6319254629779607 0.01799869234673679 0.0029185700928792357 0.04516884833574295\n",
      "337 1.6156611139886081 0.01809566665906459 0.0029244671808555723 0.04536168873310089\n",
      "338 1.6947442790260538 0.01789295009803027 0.0029390793992206455 0.046469150111079216\n",
      "339 1.6124264940153807 0.01808205363340676 0.0028883449034765364 0.04404139667749405\n",
      "340 1.6334510830347426 0.01822921948041767 0.002960740774869919 0.04558191336691379\n",
      "341 1.6880410290323198 0.01806875958573073 0.002945936773903668 0.04589692242443562\n",
      "342 1.6443172219442204 0.017862033215351403 0.0029388888971880077 0.04556687772274017\n",
      "343 1.6497567120241001 0.018293848377652466 0.0029371212469413875 0.04486624822020531\n",
      "344 1.6928690589847974 0.018219314981251955 0.002887060516513884 0.04707330167293548\n",
      "345 1.6433349719736725 0.017952702357433736 0.0029205241007730365 0.04658903405070305\n",
      "346 1.662136950995773 0.01806430157739669 0.0029509686166420577 0.045178459212183955\n",
      "347 1.6925625290023163 0.018419946776703 0.003065697802230716 0.045031321421265605\n",
      "348 1.6668762110057287 0.017808513599447906 0.00296756096649915 0.04764960780739784\n",
      "349 1.6524152010097168 0.018366363481618464 0.002994833281263709 0.04391272328794003\n",
      "350 1.6557502819923684 0.01821292599197477 0.0029793781228363513 0.04752056710422039\n",
      "351 1.683437198982574 0.01796233153436333 0.0029188171494752167 0.04475808069109917\n",
      "352 1.647393901948817 0.01819469779729843 0.00292466392274946 0.04531531557440758\n",
      "353 1.6938490890315734 0.018023116514086723 0.0029330765129998325 0.04659029208123684\n",
      "354 1.6535956919542514 0.018124044057913125 0.0029208187479525805 0.045060208439826964\n",
      "355 1.6579809809918515 0.017970586312003434 0.0029085677117109297 0.04615361802279949\n",
      "356 1.6592947010067292 0.018046113080345094 0.0029420604929327964 0.04585995376110077\n",
      "357 1.6993681090534665 0.018009036197327077 0.002909533120691776 0.04629985317587852\n",
      "358 1.6476846020086668 0.0180229697143659 0.003030465729534626 0.04824281372129917\n",
      "359 1.64925644203322 0.017917348071932793 0.0029135866323485972 0.04587334468960762\n",
      "360 1.6912559589836746 0.018526423489674926 0.0029663754859939216 0.045008376613259314\n",
      "361 1.6643605810240842 0.018030826933681965 0.002937254961580038 0.04904829636216164\n",
      "362 1.661630990973208 0.01775876560714096 0.0029726452426984905 0.04629734382033348\n",
      "363 1.6940431389957666 0.01795896014664322 0.0028851540060713886 0.0447918739169836\n",
      "364 1.6545054509770125 0.018184006097726524 0.00296073816716671 0.04583263024687767\n",
      "365 1.591189194994513 0.017837727442383766 0.0029555497458204627 0.04713706523180008\n",
      "366 1.1364276730455458 0.018088846001774073 0.0029001575661823154 0.04510512351989746\n",
      "367 1.6906015489948913 0.018326165270991623 0.0029856756096705793 0.04744254276156425\n",
      "368 1.6300294130342081 0.018729602685198188 0.00312766432762146 0.04595849886536598\n",
      "369 1.678028770023957 0.01817788532935083 0.0030131635488942266 0.048077112063765526\n",
      "370 1.6735840999754146 0.018007433507591486 0.002926894323900342 0.04534249827265739\n",
      "371 1.658430411014706 0.01818103715777397 0.002967201825231314 0.04689521044492721\n",
      "372 1.6555147509789094 0.01794290286488831 0.002908064448274672 0.046759229898452756\n",
      "373 1.693210990051739 0.01784162945114076 0.0028987603262066843 0.04571906849741936\n",
      "374 1.6644933400093578 0.018071417114697397 0.002920368674676865 0.04598546773195267\n",
      "375 1.657855090976227 0.018000364652834833 0.0029090079478919506 0.047271355614066125\n",
      "376 1.693587040004786 0.017989959567785263 0.0029398084385320543 0.04586352147161961\n",
      "377 1.6566631309688091 0.01805754692759365 0.002919706259854138 0.04614425748586655\n",
      "378 1.660649030993227 0.01820861711166799 0.0030210522236302495 0.04665254391729832\n",
      "379 1.6660989800002426 0.01813149731606245 0.002994880988262594 0.04668061770498753\n",
      "380 1.690019219997339 0.018004959216341376 0.002905745292082429 0.04594056233763695\n",
      "381 1.6558506009751 0.018255269154906273 0.002937438990920782 0.04743848219513893\n",
      "382 1.6957316389889456 0.018189332215115428 0.0029634191654622556 0.04705685675144196\n",
      "383 1.656500220997259 0.01817233278416097 0.002956394315697253 0.046809279918670656\n",
      "384 1.6586263310164213 0.01792852859944105 0.0029022690607234834 0.04614062532782555\n",
      "385 1.6826511099934578 0.01806212856899947 0.0029074778081849217 0.04624349027872086\n",
      "386 1.6751981300185435 0.01793904509395361 0.0029294925509020684 0.04769936949014664\n",
      "387 1.6606854710262269 0.018057203735224903 0.0029709471622481943 0.04588237255811691\n",
      "388 1.66082407097565 0.018571673659607768 0.0031234703259542585 0.046978143975138664\n",
      "389 1.6937764789909124 0.018093779566697776 0.002964780363254249 0.04901958629488945\n",
      "390 1.660482860985212 0.018346573575399816 0.00308357672765851 0.04463526681065559\n",
      "391 1.6842611199826933 0.018260321579873562 0.0029239068971946836 0.04803756810724735\n",
      "392 1.666705509996973 0.018066605203785002 0.0029308591736480595 0.046402058005332945\n",
      "393 1.641175172990188 0.017752600135281682 0.0029445474967360495 0.04763173758983612\n",
      "394 1.6636589900008403 0.017965962761081755 0.0029211325105279683 0.046048928052186966\n",
      "395 1.6745582810253836 0.018048266414552927 0.0028818165417760612 0.04769549965858459\n",
      "396 1.6593128810054623 0.018180651706643403 0.0029612872283905746 0.04744446612894535\n",
      "397 1.6478752020047978 0.018376955995336175 0.0030494478298351167 0.04686453863978386\n",
      "398 1.6990887579740956 0.01839796977583319 0.003196851606480777 0.046981802210211754\n",
      "399 1.6463929919991642 0.0180091307265684 0.0028589431429281833 0.045302664116024974\n",
      "400 1.6626817710348405 0.01822548673953861 0.0029487489257007836 0.0468342985957861\n",
      "401 1.6996701289899647 0.017889198032207787 0.002879661275073886 0.04763345718383789\n",
      "402 1.6458337920485064 0.017942994483746588 0.002888572239317 0.047149178385734555\n",
      "403 1.6575206310371868 0.017910589696839452 0.002876915107481182 0.047096215188503265\n",
      "404 1.699377367971465 0.01809640508145094 0.0029386205831542613 0.04603228643536568\n",
      "405 1.6650184909813106 0.017939058830961585 0.002875206037424505 0.047314489260315895\n",
      "406 1.6515144220320508 0.017892918433062732 0.0028845260851085184 0.047263240441679955\n",
      "407 1.6972030790057033 0.01804991567041725 0.002882423740811646 0.04695330411195755\n",
      "408 1.6621433009859174 0.017979482421651483 0.002885321993380785 0.04759613908827305\n",
      "409 1.6499307510093786 0.017948193824850023 0.0028762938687577843 0.047455760464072225\n",
      "410 1.6928184690186754 0.018071688478812575 0.002879022667184472 0.0469242662191391\n",
      "411 1.6628839109907858 0.018107369891367853 0.0028725134441629054 0.0467534676194191\n",
      "412 1.6660509309731424 0.017979702213779092 0.0028848290909081697 0.047623523697257045\n",
      "413 1.6642308909795247 0.017868971568532288 0.002865659352391958 0.04770269356667996\n",
      "414 1.6784541999804787 0.01798812032211572 0.002870275161694735 0.04702583774924278\n",
      "415 1.363294937997125 0.018095843610353768 0.002885068370960653 0.046580496057868\n",
      "416 1.3348631110275164 0.017960211262106895 0.0028829787857830524 0.04774927943944931\n",
      "417 1.651611270965077 0.017944674473255873 0.002889582747593522 0.04768834561109543\n",
      "418 1.6954776589991525 0.017962744110263884 0.0028648193925619124 0.0467003121972084\n",
      "419 1.6665108810411766 0.017992946784943342 0.002877221256494522 0.047245331853628156\n",
      "420 1.6872159690246917 0.017956839525140822 0.0028662058059126137 0.047404734417796135\n",
      "421 1.6598386309924535 0.01798378466628492 0.002877729223109782 0.04757484085857868\n",
      "422 1.6549161819857545 0.017957336851395667 0.0028964632423594595 0.047179564088582995\n",
      "423 1.6932893189950846 0.01798642601352185 0.0028736268635839225 0.047287165001034734\n",
      "424 1.657639320997987 0.018090913305059075 0.0028957359958440066 0.046410084888339045\n",
      "425 1.6937589289736934 0.01806814398150891 0.0028603487880900502 0.04769851788878441\n",
      "426 1.6613421610090882 0.017873368342407048 0.002874185983091593 0.04833403788506985\n",
      "427 1.6571594909764826 0.017946444102562964 0.0028796930331736804 0.04758304804563522\n",
      "428 1.6943859690218233 0.01807540189474821 0.0028755720471963287 0.04730047285556793\n",
      "429 1.6582768009975553 0.017970684682950377 0.0028759121196344495 0.04812993258237839\n",
      "430 1.6469686020282097 0.017943325801752508 0.0028638388961553574 0.04745002090930939\n",
      "431 1.6745313099818304 0.018066946766339242 0.0028746796073392034 0.047647376731038096\n",
      "432 1.658861642004922 0.018044382566586137 0.0029007327975705266 0.047469595819711684\n",
      "433 1.6522103609750047 0.018080342561006546 0.0029187565203756096 0.048027302324771884\n",
      "434 1.6550042710150592 0.017839232576079667 0.002904286002740264 0.04754548519849777\n",
      "435 1.6884339699754491 0.017975095775909722 0.002877038111910224 0.04776963889598847\n",
      "436 1.6543567910557613 0.01806350564584136 0.002885249652899802 0.047197884693741796\n",
      "437 1.660415150981862 0.01801854302175343 0.002866706345230341 0.04758788943290711\n",
      "438 1.6929228490334935 0.017861848464235663 0.0028701597591862084 0.04793789386749268\n",
      "439 1.65997865103418 0.017910846625454724 0.0028683837270364167 0.04726328626275063\n",
      "440 1.6523049719980918 0.01795319130178541 0.0028663854580372574 0.04796046540141106\n",
      "441 1.6988532789982855 0.017942886566743255 0.0028669940307736396 0.04776807278394699\n",
      "442 1.6599405509768985 0.017966664163395762 0.002876906911842525 0.04771047979593277\n",
      "443 1.6749075899715535 0.018062762217596173 0.00287129411008209 0.04734637178480625\n",
      "444 1.6647745000082068 0.017955042072571814 0.002868673764169216 0.0485371220856905\n",
      "445 1.652994031959679 0.017875566030852497 0.0028671308886259795 0.047945763915777206\n",
      "446 1.6433556120027788 0.01795286638662219 0.0028581857681274415 0.0477469377219677\n",
      "447 1.6926902389968745 0.018103546579368412 0.0028952789958566426 0.047705985605716705\n",
      "448 1.6539133620099165 0.018068672972731292 0.0028631688095629216 0.047417164966464045\n",
      "449 1.6555907709989697 0.01797730557154864 0.0028923195553943516 0.04776167348027229\n",
      "450 1.688450379006099 0.017972486093640327 0.002875443152152002 0.04868318736553192\n",
      "451 1.6527084419503808 0.017885914887301624 0.0028839478269219398 0.047611258924007416\n",
      "452 1.6545700909919105 0.017971009947359562 0.0028616939904168247 0.04785402193665504\n",
      "453 1.6711589799961075 0.018088378245010972 0.0028831812553107737 0.04791553169488907\n",
      "454 1.647339581977576 0.018021232914179564 0.00288262281101197 0.04737786762416363\n",
      "455 1.6693255809950642 0.017918342957273126 0.002856371970847249 0.04789247326552868\n",
      "456 1.6561637109844014 0.01786980708129704 0.0028771029552444815 0.04873502776026726\n",
      "457 1.6596082809846848 0.017960386583581567 0.0028896744595840575 0.04692179709672928\n",
      "458 1.6612615310004912 0.018028856604360044 0.0028796596685424446 0.04805312976241112\n",
      "459 1.692119689018 0.017907201661728323 0.002856766898185015 0.04774923175573349\n",
      "460 1.65877342101885 0.017986020306125283 0.0028728616889566183 0.04849576577544212\n",
      "461 1.6578101710183546 0.017893795855343342 0.002861504931934178 0.048589051887393\n",
      "462 1.6870241199503653 0.01807836175430566 0.0028732379898428915 0.04775669798254967\n",
      "463 1.6626630409737118 0.018025779514573514 0.002869792771525681 0.04864921234548092\n",
      "464 1.6632569109788164 0.017953329370357096 0.0028608650900423527 0.04802868515253067\n",
      "465 1.6862889389740303 0.018013520748354495 0.002864028559997678 0.048160869628190994\n",
      "466 1.1318499330081977 0.017970028915442526 0.0028592866845428945 0.04780979230999947\n",
      "467 1.5484353469801135 0.01797648472711444 0.0028589765075594186 0.04754925817251206\n",
      "468 1.6543012120528147 0.01794582954607904 0.0028580627404153347 0.04804119691252708\n",
      "469 1.6913863790105097 0.017928027431480587 0.002868426381610334 0.04866913370788097\n",
      "470 1.640697232040111 0.017958240816369653 0.002862889948301017 0.04803022742271423\n",
      "471 1.6582066310220398 0.018025737372227013 0.0028733805287629367 0.048340309783816336\n",
      "472 1.6582992210169323 0.018046186887659132 0.0028677766211330892 0.04834346249699593\n",
      "473 1.6968249889905564 0.01810760225635022 0.002888606837950647 0.04768318310379982\n",
      "474 1.6352663330035284 0.018030923907645047 0.0028906709514558314 0.04882152788341045\n",
      "475 1.6895946789882146 0.017964819446206093 0.002889388264156878 0.048265565559267996\n",
      "476 1.6454071719781496 0.01787077949848026 0.002887525246478617 0.04803768284618855\n",
      "477 1.6224905329872854 0.01798165892250836 0.0028572236420586704 0.048024585098028184\n",
      "478 1.6856305499677546 0.01799256820231676 0.0028556376462802293 0.048273232951760295\n",
      "479 1.6626333309686743 0.017922226106747985 0.0028734611580148338 0.04886250123381615\n",
      "480 1.6557949210400693 0.01795293448958546 0.0028845548164099454 0.04822517409920692\n",
      "481 1.69506168900989 0.017904022010043263 0.0028684660326689483 0.048391954600811006\n",
      "482 1.6484100820380263 0.0179812676506117 0.0028610853478312492 0.04813045784831047\n",
      "483 1.6454426620039158 0.017960655270144343 0.0028549028327688577 0.04883910156786442\n",
      "484 1.6940064890077338 0.01809269783552736 0.0028909762157127263 0.047744208574295045\n",
      "485 1.6581950809923 0.017997919698245823 0.0028602333506569265 0.04930366352200508\n",
      "486 1.6454620119766332 0.01797722850460559 0.002872551674954593 0.04822850972414017\n",
      "487 1.690875808999408 0.01809160807169974 0.0028573683928698303 0.04824892580509186\n",
      "488 1.650040822045412 0.018053935142233968 0.002895869500935078 0.049110322073101995\n",
      "489 1.6607793610310182 0.017836787621490657 0.0028469170909374954 0.0485806442797184\n",
      "490 1.694165578985121 0.01805347134359181 0.002904612198472023 0.04807316921651363\n",
      "491 1.662092061014846 0.017996671493165195 0.0028738075867295264 0.0484068788588047\n",
      "492 1.6510217310278676 0.01788984367158264 0.002853216277435422 0.04859919399023056\n",
      "493 1.6817807700135745 0.0178840922890231 0.0028704424155876042 0.04913819171488285\n",
      "494 1.6493304320028983 0.017979849595576525 0.0028580898651853204 0.04778303615748882\n",
      "495 1.6537529909983277 0.017948109656572342 0.002854696777649224 0.048917029052972794\n",
      "496 1.689438229019288 0.017900314182043076 0.0028525157365947964 0.04833515994250774\n",
      "497 1.637699943035841 0.018011177890002728 0.002854140684939921 0.04876555949449539\n",
      "498 1.6358089720015414 0.017970224609598517 0.0028457465348765256 0.04874521009624004\n",
      "499 1.6982956690480933 0.017960320692509413 0.0028745435876771806 0.048522359877824786\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "# training and evaluation\n",
    "################################################################\n",
    "model = FNO3d(modes, modes, modes, width).cuda()\n",
    "\n",
    "print(count_params(model))\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "y_normalizer.cuda()\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).view(batch_size, S1, S2, T)\n",
    "\n",
    "        mse = F.mse_loss(out, y, reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        y = y_normalizer.decode(y)\n",
    "        out = y_normalizer.decode(out)\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x).view(batch_size, S1, S2, T)\n",
    "            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_mse, train_l2, test_l2)\n",
    "torch.save(model, path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0028939382173120975\n",
      "0 0.0031722562853246927\n",
      "0 0.003015394089743495\n",
      "0 0.0026928673032671213\n",
      "0 0.005330904386937618\n",
      "0 0.005310556851327419\n",
      "0 0.007893813773989677\n",
      "0 0.015834152698516846\n",
      "0 0.023340536281466484\n",
      "0 0.030501900240778923\n",
      "0 0.0676659494638443\n",
      "0 0.07207871973514557\n",
      "0 0.075888991355896\n",
      "0 0.07894236594438553\n",
      "0 0.08101623505353928\n",
      "0 0.08544118702411652\n",
      "0 0.09304835647344589\n",
      "0 0.0995858758687973\n",
      "0 0.10557994991540909\n",
      "0 0.11121329665184021\n"
     ]
    }
   ],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "\n",
    "index = 0\n",
    "# model = torch.load(\"model/fluidity_ep500\")\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "first_output = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        if index == 0:\n",
    "            first_output = y.clone()\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(out[:,:,:,0])\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "        print(index, test_l2)\n",
    "\n",
    "        # cp = plt.imshow(pred[index])\n",
    "        # plt.colorbar(cp)\n",
    "        # plt.show()\n",
    "\n",
    "# for i in range(18):\n",
    "#     cp = plt.imshow(abs(pred[0,:,:,i]-first_output[0,:,:,i]))\n",
    "#     plt.colorbar(cp)\n",
    "#     plt.show()\n",
    "#     print(i)\n",
    "    # cp = plt.imshow(first_output[0,:,:,i])\n",
    "    # plt.colorbar(cp)\n",
    "    # plt.show()\n",
    "\n",
    "# cp = plt.imshow(first_output[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(pred[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(pred[0,:,:,0]-first_output[0,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(pred[0,:,:,9])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "# cp = plt.imshow(pois_output[0,:,:,0])\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n",
    "\n",
    "# cp = plt.imshow(abs(pred[index][:,:,0] - pois_output[0,:,:,0]))\n",
    "# plt.colorbar(cp)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f8c49416430bf6f9356715c0a0173afd7466c7f6261729e3b70b73af4f7e4ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
